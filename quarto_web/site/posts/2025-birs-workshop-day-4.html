<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-21">
<meta name="description" content="Thursday, August 21 Â· Day 4 of the 2025 BIRS Workshop â€œFoundation Models and Their Biomedical Applications: Bridging the Gapâ€">

<title>2025 Workshop at BIRS: Day 4 Recordings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../img/logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#workshop-at-birs-overview" id="toc-workshop-at-birs-overview" class="nav-link active" data-scroll-target="#workshop-at-birs-overview">ğŸ 2025 Workshop at BIRS: Overview</a>
  <ul>
  <li><a href="#foundation-models-and-their-biomedical-applications-bridging-the-gap" id="toc-foundation-models-and-their-biomedical-applications-bridging-the-gap" class="nav-link" data-scroll-target="#foundation-models-and-their-biomedical-applications-bridging-the-gap">Foundation Models and Their Biomedical Applications: Bridging the Gap</a></li>
  <li><a href="#talks-quick-looks-full-notes-recordings" id="toc-talks-quick-looks-full-notes-recordings" class="nav-link" data-scroll-target="#talks-quick-looks-full-notes-recordings"><small><em>ğŸ¬ Talks â€” <span style="font-weight:normal;">Quick Looks, Full Notes &amp; Recordings</span></em></small></a></li>
  </ul></li>
  <li><a href="#day-4-recordings-morning-session" id="toc-day-4-recordings-morning-session" class="nav-link" data-scroll-target="#day-4-recordings-morning-session">â–¶ï¸ Day 4 Recordings: Morning Session</a>
  <ul>
  <li><a href="#talk-chengchun-shi-reinforcement-learning-methodologies-and-applications-a-selective-overview" id="toc-talk-chengchun-shi-reinforcement-learning-methodologies-and-applications-a-selective-overview" class="nav-link" data-scroll-target="#talk-chengchun-shi-reinforcement-learning-methodologies-and-applications-a-selective-overview">ğŸ¤ Chengchun Shi: <em>Reinforcement Learning Methodologies and Applications: A Selective Overview</em></a></li>
  <li><a href="#talk-linjun-zhang-statistical-perspectives-on-emerging-challenges-in-large-language-models" id="toc-talk-linjun-zhang-statistical-perspectives-on-emerging-challenges-in-large-language-models" class="nav-link" data-scroll-target="#talk-linjun-zhang-statistical-perspectives-on-emerging-challenges-in-large-language-models">ğŸ¤ Linjun Zhang: <em>Statistical Perspectives on Emerging Challenges in Large Language Models</em></a></li>
  <li><a href="#talk-heping-zhang-change-point-based-regional-association-scoring-in-genome-wide-association-studies" id="toc-talk-heping-zhang-change-point-based-regional-association-scoring-in-genome-wide-association-studies" class="nav-link" data-scroll-target="#talk-heping-zhang-change-point-based-regional-association-scoring-in-genome-wide-association-studies">ğŸ¤ Heping Zhang: <em>Change Point-Based Regional Association Scoring in Genome-wide Association Studies</em></a></li>
  <li><a href="#talk-kaixian-yu-constructing-a-large-scale-biomedical-knowledge-graph-and-its-applications-in-drug-discovery" id="toc-talk-kaixian-yu-constructing-a-large-scale-biomedical-knowledge-graph-and-its-applications-in-drug-discovery" class="nav-link" data-scroll-target="#talk-kaixian-yu-constructing-a-large-scale-biomedical-knowledge-graph-and-its-applications-in-drug-discovery">ğŸ¤ Kaixian Yu: <em>Constructing a Large-Scale Biomedical Knowledge Graph and Its Applications in Drug Discovery</em></a></li>
  </ul></li>
  <li><a href="#day-4-recordings-afternoon-session" id="toc-day-4-recordings-afternoon-session" class="nav-link" data-scroll-target="#day-4-recordings-afternoon-session">â–¶ï¸ Day 4 Recordings: Afternoon Session</a>
  <ul>
  <li><a href="#talk-jeffrey-zhang-agentic-ai-for-healthcare-scheduling-ï¿½-a-use-case-on-optimizing-anesthesiology-staff-scheduling-in-surgery-rooms" id="toc-talk-jeffrey-zhang-agentic-ai-for-healthcare-scheduling-ï¿½-a-use-case-on-optimizing-anesthesiology-staff-scheduling-in-surgery-rooms" class="nav-link" data-scroll-target="#talk-jeffrey-zhang-agentic-ai-for-healthcare-scheduling-ï¿½-a-use-case-on-optimizing-anesthesiology-staff-scheduling-in-surgery-rooms">ğŸ¤ Jeffrey Zhang: <em>Agentic AI for Healthcare Scheduling â€” A Use Case on Optimizing Anesthesiology Staff Scheduling in Surgery Rooms</em></a></li>
  <li><a href="#talk-elena-tuzhilina-statistical-curve-models-for-inferring-3d-chromatin-architecture" id="toc-talk-elena-tuzhilina-statistical-curve-models-for-inferring-3d-chromatin-architecture" class="nav-link" data-scroll-target="#talk-elena-tuzhilina-statistical-curve-models-for-inferring-3d-chromatin-architecture">ğŸ¤ Elena Tuzhilina: <em>Statistical Curve Models for Inferring 3D Chromatin Architecture</em></a></li>
  <li><a href="#talk-xin-wang-medical-image-foundation-models-and-their-applications" id="toc-talk-xin-wang-medical-image-foundation-models-and-their-applications" class="nav-link" data-scroll-target="#talk-xin-wang-medical-image-foundation-models-and-their-applications">ğŸ¤ Xin Wang: <em>Medical Image Foundation Models and Their Applications</em></a></li>
  <li><a href="#talk-edgar-dobriban-synthetic-powered-predictive-inference" id="toc-talk-edgar-dobriban-synthetic-powered-predictive-inference" class="nav-link" data-scroll-target="#talk-edgar-dobriban-synthetic-powered-predictive-inference">ğŸ¤ Edgar Dobriban: <em>Synthetic-Powered Predictive Inference</em></a></li>
  <li><a href="#talk-bingxin-zhao-ai-co-scientist-in-protein-disease-reasoning" id="toc-talk-bingxin-zhao-ai-co-scientist-in-protein-disease-reasoning" class="nav-link" data-scroll-target="#talk-bingxin-zhao-ai-co-scientist-in-protein-disease-reasoning">ğŸ¤ Bingxin Zhao: <em>AI Co-scientist in Protein-disease Reasoning</em></a></li>
  </ul></li>
  <li><a href="#watch-all-recordings" id="toc-watch-all-recordings" class="nav-link" data-scroll-target="#watch-all-recordings">ğŸ“Œ Watch All Recordings</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">2025 Workshop at BIRS: Day 4 Recordings</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Events</div>
    <div class="quarto-category">Videos</div>
  </div>
  </div>

<div>
  <div class="description">
    Thursday, August 21 Â· Day 4 of the 2025 BIRS Workshop <strong>â€œFoundation Models and Their Biomedical Applications: Bridging the Gapâ€</strong>
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<style>
  .yt-thumb-card{display:flex; align-items:center; justify-content: center; gap:12px;}
  .yt-thumb-card .avatar{width:56px; height:56px; border-radius:50%;}
  .yt-thumb-card .thumb{width:260px; aspect-ratio:16/9; object-fit:cover; border-radius:10px;}
</style>
<!--A minimal thumbnail:-->
<div style="text-align: center; justify-content: center; margin-bottom: 2em;">
<a class="yt-thumb-card" href="https://www.youtube.com/@StatsUpAI" target="_blank"> <img class="avatar" src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj" alt="Stats Up AI" style="width: 20%; height: 20%;"> </a> <a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"> <img src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" alt="Stats Up AI YouTube" width="15%">
<p style="font-size: 14px; margin-top: 0.5em;">
Visit the <strong>Stats Up AI</strong> Channel for More
</p>
</a><p><a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"></a> <!--</div>--></p>
<!--An inline frame (iframe) to embed the YouTube playlist:-->
<!--<div style="text-align: center; margin-top: 1em;">-->
<!--<iframe -->
<!--  max-width="560px"-->
<!--  width="100%"-->
<!--  aspect-ratio="16/9"-->
<!--  src="https://www.youtube.com/embed/videoseries?list=UU2VlJBtA_63CrXP0Sr99P8Q" -->
<!--  title="Uploads playlist"-->
<!--  frameborder="0"-->
<!--  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" -->
<!--  allowfullscreen>-->
<!--</iframe>-->
<!--</div>-->
</div>
<!--YouTube logo:-->
<!--src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" -->
<!--Channel avatar:-->
<!--src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj"-->
<section id="workshop-at-birs-overview" class="level2">
<h2 class="anchored" data-anchor-id="workshop-at-birs-overview">ğŸ 2025 Workshop at BIRS: Overview</h2>
<section id="foundation-models-and-their-biomedical-applications-bridging-the-gap" class="level3">
<h3 class="anchored" data-anchor-id="foundation-models-and-their-biomedical-applications-bridging-the-gap">Foundation Models and Their Biomedical Applications: Bridging the Gap</h3>
<!--**Location:** -->
<p>ğŸ“ Banff International Research Station (BIRS), Banff, Alberta, Canada<br>
<strong>Event Website:</strong> <a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470">2025 Workshop Homepage</a> Â· <strong>Dates:</strong> Aug 17â€“22, 2025</p>
</section>
<section id="talks-quick-looks-full-notes-recordings" class="level3">
<h3 class="anchored" data-anchor-id="talks-quick-looks-full-notes-recordings"><small><em>ğŸ¬ Talks â€” <span style="font-weight:normal;">Quick Looks, Full Notes &amp; Recordings</span></em></small></h3>
<div style="margin-left:20px; margin-bottom:-10px">
<small> â®• Full program: <a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/schedule">2025 Workshop Schedule</a> </small>
</div>
<p><small></small></p><small>
<ul>
<li>ğŸ”— <a href="../posts/2025-birs-workshop-day-1.html"><strong>2025 Workshop at BIRS: Day 1</strong> Recordings</a> (Monday, Aug 18)<br>
</li>
<li>ğŸ”— <a href="../posts/2025-birs-workshop-day-2.html"><strong>2025 Workshop at BIRS: Day 2</strong> Recordings</a> (Tuesday, Aug 19)<br>
</li>
<li>ğŸ”— <a href="../posts/2025-birs-workshop-day-3.html"><strong>2025 Workshop at BIRS: Day 3</strong> Recordings</a> (Wednesday, Aug 20)<br>
</li>
<li>ğŸ“– <strong>2025 Workshop at BIRS: Day 4</strong> Recordings (Thursday, Aug 21) ğŸ‘ˆ</li>
</ul>
</small><p><small></small></p>
<div style="text-align:left; margin-bottom: 50px; margin-top: 20px">
<p><small style="text-align:left; border-bottom: 1px dashed #ddd;"> <em><strong>â†©ï¸</strong> Read more on <strong>Stats Up AI</strong> <a href="https://statsupai.org/community-news.html"><span style="color: #3C898A"><strong>ğŸ“° Community News</strong></span></a></em> </small></p>
</div>
</section>
</section>
<section id="day-4-recordings-morning-session" class="level2">
<h2 class="anchored" data-anchor-id="day-4-recordings-morning-session">â–¶ï¸ Day 4 Recordings: Morning Session</h2>
<section id="talk-chengchun-shi-reinforcement-learning-methodologies-and-applications-a-selective-overview" class="level3">
<h3 class="anchored" data-anchor-id="talk-chengchun-shi-reinforcement-learning-methodologies-and-applications-a-selective-overview">ğŸ¤ Chengchun Shi: <em>Reinforcement Learning Methodologies and Applications: A Selective Overview</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 09:03 - 09:33<br>
ğŸ›ï¸ London School of Economics and Political Science</p>
<strong>Keywords:</strong> policy optimization, causal reinforcement learning, human feedback, healthcare applications<br>

<strong>Summary:</strong> A selective overview of reinforcement learning highlights recent advances in policy optimization, causal RL, and RL from human feedback, with applications spanning AI and healthcare.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Reinforcement Learning (RL) has
emerged as a powerful paradigm for sequential decision-making, enabling
agents to learn optimal policies through interaction with their
environments. Over the past decade, it has been one of the most popular
research directions in machine learning and AI. This talk provides a
selective overview of RL methodologies, including policy optimization,
policy evaluation, model validation, causal RL, RL from human feedback,
along with their applications in AI and healthcare. The goal is to equip
the audience with both a conceptual understanding of the diverse ways RL
can be leveraged in real practice.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508210903-Shi.mp4" title="BIRS talk: Chengchun Shi" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508210903-Shi.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-linjun-zhang-statistical-perspectives-on-emerging-challenges-in-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="talk-linjun-zhang-statistical-perspectives-on-emerging-challenges-in-large-language-models">ğŸ¤ Linjun Zhang: <em>Statistical Perspectives on Emerging Challenges in Large Language Models</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 09:35 - 10:11<br>
ğŸ›ï¸ Rutgers University, New Brunswick</p>
<strong>Keywords:</strong> data attribution, statistical post-processing, safety alignment, methodology for LLMs<br>

<strong>Summary:</strong> Statistical approaches are proposed to detect data misappropriation in LLM outputs and to post-process models for safety and alignment, framing a broader agenda for statisticians in AI.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Large Language Models (LLMs) have
transformed the landscape of artificial intelligence, yet they raise a
host of new methodological, ethical, and practical challenges that are
fundamentally statistical in nature. In this talk, I will highlight how
statistical thinking can contribute to understanding and improving LLMs,
focusing on two concrete problems: detecting data misappropriation in
model outputs, and post-processing LLMs to ensure safety and alignment.
I will also offer broader reflections on the role of statisticians in
shaping the future of LLMs and AI, and suggest potential directions for
impactful research at this interface.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508210935-Zhang.mp4" title="BIRS talk: Linjun Zhang" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508210935-Zhang.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-heping-zhang-change-point-based-regional-association-scoring-in-genome-wide-association-studies" class="level3">
<h3 class="anchored" data-anchor-id="talk-heping-zhang-change-point-based-regional-association-scoring-in-genome-wide-association-studies">ğŸ¤ Heping Zhang: <em>Change Point-Based Regional Association Scoring in Genome-wide Association Studies</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 10:31 - 11:04<br>
ğŸ›ï¸ Yale University</p>
<strong>Keywords:</strong> regional association, change point detection, GWAS, statistical power<br>

<strong>Summary:</strong> A change point detection framework improves regional association testing in GWAS, boosting power under sparse causal variants and lowering false positives compared with existing methods.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Genome-wide association studies are
essential for uncovering single nucleotide polymorphisms (SNPs)
associated with complex diseases. However, current approaches often
struggle to detect regional associations, especially when individual
variant effects are small and widely dispersed, leading to limited
statistical power and inflated type I error rates. We propose a novel
and powerful method that addresses these challenges by first quantifying
the regional association strength at each single nucleotide
polymorphism. These values are then transformed into a time series,
allowing us to apply change point detection techniques to identify
significant genomic regions. Through extensive simulations, our method
consistently outperforms existing approaches, showing over a 20%
improvement in power under difficult scenariosâ€”particularly when causal
variants are sparse and multiple association regions co-exist. It also
achieves a notably lower false positive rate across all tested
conditions. We further demonstrate the effectiveness of our approach
using data from the Adolescent Brain Cognitive Developmentâ„  (ABCDÂ®)
study, identifying genomic regions associated with the Brief Problem
Monitor. This work is a collaboration with Dr.&nbsp;Yiran Jiang.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508211031-Zhang.mp4" title="BIRS talk: Heping Zhang" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508211031-Zhang.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-kaixian-yu-constructing-a-large-scale-biomedical-knowledge-graph-and-its-applications-in-drug-discovery" class="level3">
<h3 class="anchored" data-anchor-id="talk-kaixian-yu-constructing-a-large-scale-biomedical-knowledge-graph-and-its-applications-in-drug-discovery">ğŸ¤ Kaixian Yu: <em>Constructing a Large-Scale Biomedical Knowledge Graph and Its Applications in Drug Discovery</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 11:00 - 11:30<br>
ğŸ›ï¸ Insilicom LLC, Tallahassee, FL, USA</p>
<strong>Keywords:</strong> knowledge graph construction, information extraction, causal inference, drug discovery<br>

<strong>Summary:</strong> A large-scale biomedical knowledge graph (iKraph) built from PubMed abstracts and integrated databases achieves human-level accuracy in knowledge extraction and supports applications from drug repurposing to causal inference.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <!--video_src="https://videos.birs.ca/2025/25w5470/20250821[]-Yu.mp4"-->
<!--video_link="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/20250821[]-Yu.html"}-->
<p><strong>Introduction:</strong> The exponential growth of biomedical
literature necessitates advanced tools for efficient knowledge
integration and discovery. Knowledge graphs (KGs) have emerged as a
powerful solution, yet transforming unstructured text into accurate,
structured representations remains a major challenge. In this talk, we
present iKraph, a large-scale biomedical KG constructed using an
award-winning information extraction pipeline applied to all PubMed
abstracts. Our approach achieves human-level accuracy in knowledge
extraction, surpassing manually curated databases in coverage. To
enhance comprehensiveness, we integrated relations from 40 public
databases and high-throughput genomics data, enabling rigorous
evaluation of automated knowledge discovery. We further developed an
interpretable, probabilistic inference method to identify indirect
causal relationships, demonstrating its utility in real-time COVID-19
drug repurposing. To facilitate broader use, we provide a cloud-based
platform (https://biokde.insilicom.com) offering access to this
structured knowledge and analytical tools. This work highlights the
transformative potential of high-accuracy KGs in accelerating biomedical
research and drug discovery.</p>
</details>
</section>
</section>
<section id="day-4-recordings-afternoon-session" class="level2">
<h2 class="anchored" data-anchor-id="day-4-recordings-afternoon-session">â–¶ï¸ Day 4 Recordings: Afternoon Session</h2>
<section id="talk-jeffrey-zhang-agentic-ai-for-healthcare-scheduling-ï¿½-a-use-case-on-optimizing-anesthesiology-staff-scheduling-in-surgery-rooms" class="level3">
<h3 class="anchored" data-anchor-id="talk-jeffrey-zhang-agentic-ai-for-healthcare-scheduling-ï¿½-a-use-case-on-optimizing-anesthesiology-staff-scheduling-in-surgery-rooms">ğŸ¤ Jeffrey Zhang: <em>Agentic AI for Healthcare Scheduling â€” A Use Case on Optimizing Anesthesiology Staff Scheduling in Surgery Rooms</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 13:24 - 13:40<br>
ğŸ›ï¸ Yale University</p>
<strong>Keywords:</strong> agentic AI, healthcare operations, staff scheduling, optimization<br>

<strong>Summary:</strong> An agentic AI system optimizes anesthesiology staff scheduling across operating rooms, reducing idle time, cutting costs, and improving adaptability to real-time hospital constraints.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> We present ongoing work for the
development of an agentic AI system to optimize anesthesiology staff
scheduling across Yale-New Haven Hospitalâ€™s multi-site operating rooms.
Manual scheduling processes currently consume significant clinical and
administrative time, contribute to inefficiencies, and limit
adaptability to real-time changes. By automating daily assignments,
forecasting Certified Registered Nurse Anesthetist (CRNA) availability,
and optimizing long-horizon staffing plans, this system could reduce OR
idle time, cut locum costs, and reclaim over $1M annually in clinician
time. Our agentic AI framework consists of coordinated modules each
functioning as a decision-making agent that dynamically forecasts
demand, assigns staff, and adapts schedules in real-time based on
constraints and availability.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508211324-Zhang.mp4" title="BIRS talk: Jeffrey Zhang" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508211324-Zhang.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-elena-tuzhilina-statistical-curve-models-for-inferring-3d-chromatin-architecture" class="level3">
<h3 class="anchored" data-anchor-id="talk-elena-tuzhilina-statistical-curve-models-for-inferring-3d-chromatin-architecture">ğŸ¤ Elena Tuzhilina: <em>Statistical Curve Models for Inferring 3D Chromatin Architecture</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 13:45 - 14:06<br>
ğŸ›ï¸ University of Toronto</p>
<strong>Keywords:</strong> chromatin architecture, spline models, Hi-C data, distribution-based scaling<br>

<strong>Summary:</strong> Spline-based statistical curve models combined with distribution-based metric scaling more accurately reconstruct 3D chromatin architecture from Hi-C data, including sparse single-cell assays.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Reconstructing three-dimensional (3D)
chromatin structure from conformation capture assays (such as Hi-C) is a
critical task in computational biology, since chromatin spatial
architecture plays a vital role in numerous cellular processes and
direct imaging is challenging. Most existing algorithms that operate on
Hi-C contact matrices produce reconstructed 3D configurations in the
form of a polygonal chain. However, none of the methods exploit the fact
that the target solution is a (smooth) curve in 3D: this contiguity
attribute is either ignored or indirectly addressed by imposing spatial
constraints that are challenging to formulate. In this paper we develop
both B-spline and smoothing spline techniques for directly capturing
this potentially complex 1D curve. We subsequently combine these
techniques with a Poisson model for contact counts and compare their
performance on a real data example. In addition, motivated by the
sparsity of Hi-C contact data, especially when obtained from single-cell
assays, we appreciably extend the class of distributions used to model
contact counts. We build a general distribution-based metric scaling (
DBMS ) framework from which we develop zero-inflated and Hurdle Poisson
models as well as negative binomial applications. Illustrative
applications make recourse to bulk Hi-C data from IMR90 cells and
single-cell Hi-C data from mouse embryonic stem cells.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508211345-Tuzhilina.mp4" title="BIRS talk: Elena Tuzhilina" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508211345-Tuzhilina.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-xin-wang-medical-image-foundation-models-and-their-applications" class="level3">
<h3 class="anchored" data-anchor-id="talk-xin-wang-medical-image-foundation-models-and-their-applications">ğŸ¤ Xin Wang: <em>Medical Image Foundation Models and Their Applications</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 14:09 - 14:36<br>
ğŸ›ï¸ University at Albany, State University of New York</p>
<strong>Keywords:</strong> foundation models, medical image segmentation, image registration, precision diagnosis<br>

<strong>Summary:</strong> Medical image foundation models enable scalable segmentation and registration, driving advances in precision diagnosis and clinical decision-making across diverse imaging tasks.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Foundation models are revolutionizing
medical artificial intelligence (AI) by enabling scalable, adaptable,
and generalizable solutions across a broad spectrum of clinical tasks.
This talk will explore recent advances in Medical Image Foundation
Models, with a particular focus on two core tasks: medical image
segmentation and medical image registration. I will begin by introducing
the concept of foundation models within the medical imaging domain,
emphasizing their ability to learn rich, transferable representations
from large and heterogeneous datasets. The presentation will conclude
with real-world applications of these models, highlighting their role in
AI-driven heart disease diagnosis and analysis, and their potential to
support precision medicine and clinical decision-making.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508211409-Wang.mp4" title="BIRS talk: Xin Wang" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508211409-Wang.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-edgar-dobriban-synthetic-powered-predictive-inference" class="level3">
<h3 class="anchored" data-anchor-id="talk-edgar-dobriban-synthetic-powered-predictive-inference">ğŸ¤ Edgar Dobriban: <em>Synthetic-Powered Predictive Inference</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 14:20 - 14:40<br>
ğŸ›ï¸ University of Pennsylvania</p>
<strong>Keywords:</strong> predictive inference, conformal prediction, synthetic data, score transport<br>

<strong>Summary:</strong> Synthetic-powered predictive inference (SPI) leverages synthetic data and quantile score transport to tighten conformal prediction sets while preserving finite-sample coverage in data-scarce settings.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <!--video_src="https://videos.birs.ca/2025/25w5470/20250821[]-Dobriban.mp4"-->
<!--video_link="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/20250821[]-Dobriban.html"}-->
<p><strong>Introduction:</strong> Synthetic data, for instance generated
by foundation models, may offer great opportunities to boost sample
sizes in statistical analysis. However, the distribution of synthetic
data may not be exactly the same as that of the real data, thus
incurring the risk of faulty inferences. Motivated by these
observations, we study how to use synthetic data in a fundamental
statistical setting, that of predictive inference, i.e., predicting
future classes or outcomes with prediction sets. The standard approach
in the field, conformal prediction, tends to provide uninformative
prediction sets when calibration data are scarce. This paper introduces
Synthetic-powered predictive inference (SPI), a novel framework that
incorporates synthetic dataâ€”e.g., from a generative modelâ€”to improve
sample efficiency. At the core of our method is a score transporter: an
empirical quantile mapping that aligns nonconformity scores from
trusted, real data with those from synthetic data. By carefully
integrating the score transporter into the calibration process, SPI
provably achieves finite-sample coverage guarantees without making any
assumptions about the real and synthetic data distributions. When the
score distributions are well aligned, SPI yields substantially tighter
and more informative prediction sets than standard conformal prediction.
Experiments on image classificationâ€”augmenting data with synthetic
diffusion-model generated imagesâ€”and on the medical expenditure panel
survey (MEPS) dataset demonstrate notable improvements in predictive
efficiency in data-scarce settings.</p>
</details>
</section>
<section id="talk-bingxin-zhao-ai-co-scientist-in-protein-disease-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="talk-bingxin-zhao-ai-co-scientist-in-protein-disease-reasoning">ğŸ¤ Bingxin Zhao: <em>AI Co-scientist in Protein-disease Reasoning</em></h3>
<p>ğŸ“… Thursday, August 21, 2025 â€¢ ğŸ•˜ 14:39 - 15:06<br>
ğŸ›ï¸ University of Pennsylvania</p>
<strong>Keywords:</strong> AI co-scientist, proteinâ€“disease associations, knowledge synthesis, pathway reasoning<br>

<strong>Summary:</strong> An AI co-scientist framework integrates LLMs with domain-specific tools to automate proteinâ€“disease reasoning, scaling literature synthesis and pathway analysis for biomedical discovery.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> The rapid expansion of large-scale
proteomic resources has enabled the discovery of thousands of
protein-phenotype associations. Yet, the scientific bottleneck lies in
translating these vast summary-level statistics into structured
biological insight and actionable knowledge. This talk introduces an AI
co-scientist framework designed to scale the human reasoning process of
protein-disease interpretation. Drawing inspiration from the way human
researchers integrate statistical findings with prior scientific
knowledge, our agentic system performs a multi-stage workflow: planning
report sections, querying curated knowledge bases, reasoning over
pathway enrichment and literature evidence, and generating text-based
summaries. The system combines domain-specific tools with large language
models in a united paradigm to automate knowledge synthesis at scale. We
demonstrate applications across various diseases, highlighting how AI
co-scientists can accelerate biomedical discovery, enhance
reproducibility, and support drug development through more systematic
and scalable scientific writing.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508211439-Zhao.mp4" title="BIRS talk: Bingxin Zhao" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508211439-Zhao.html">ğŸ¬Open the video directly</a></p>
</section>
</section>
<section id="watch-all-recordings" class="level2">
<h2 class="anchored" data-anchor-id="watch-all-recordings">ğŸ“Œ Watch All Recordings</h2>
<ul>
<li><strong>StatsUpAI YouTube Channel:</strong> <a href="https://www.youtube.com/@StatsUpAI">Subscribe for updates</a></li>
<li><strong>BIRS Official Videos Page:</strong> <a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos">2025 Workshop Videos</a></li>
<li><strong>Direct Video Downloads:</strong> <a href="https://videos.birs.ca/2025/25w5470/">BIRS Video Server</a></li>
</ul>
<!------->
<style>
  .yt-thumb-card{display:flex; align-items:center; justify-content: center; gap:12px;}
  .yt-thumb-card .avatar{width:56px; height:56px; border-radius:50%;}
  .yt-thumb-card .thumb{width:260px; aspect-ratio:16/9; object-fit:cover; border-radius:10px;}
</style>
<!--A minimal thumbnail:-->
<div style="text-align: center; justify-content: center; margin-bottom: 2em;">
<a class="yt-thumb-card" href="https://www.youtube.com/@StatsUpAI" target="_blank"> <img class="avatar" src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj" alt="Stats Up AI" style="width: 20%; height: 20%;"> </a> <a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"> <img src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" alt="Stats Up AI YouTube" width="15%">
<p style="font-size: 14px; margin-top: 0.5em;">
Visit the <strong>Stats Up AI</strong> Channel for More
</p>
</a><p><a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"></a> <!--</div>--></p>
<!--An inline frame (iframe) to embed the YouTube playlist:-->
<!--<div style="text-align: center; margin-top: 1em;">-->
<!--<iframe -->
<!--  max-width="560px"-->
<!--  width="100%"-->
<!--  aspect-ratio="16/9"-->
<!--  src="https://www.youtube.com/embed/videoseries?list=UU2VlJBtA_63CrXP0Sr99P8Q" -->
<!--  title="Uploads playlist"-->
<!--  frameborder="0"-->
<!--  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" -->
<!--  allowfullscreen>-->
<!--</iframe>-->
<!--</div>-->
</div>
<!--YouTube logo:-->
<!--src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" -->
<!--Channel avatar:-->
<!--src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj"-->
<p><em>AI is rapidly reshaping biomedical research by integrating diverse data, accelerating discovery, and supporting decision-making under uncertainty. With statisticians at the forefront, these applications gain the depth, rigor, and reliability needed to truly transform science and medicine.</em></p>


</section>

</main> <!-- /main -->
<!-- GoatCounter Tracker -->
<script data-goatcounter="https://statsupai.goatcounter.com/count" async="" src="//gc.zgo.at/count.js"></script>

<!-- Per-Page View Counter (Footer Style) -->
<style>
#goatcounter-footer {
  --gc-counter-color: #2b786bef;
  display: flex; 
  align-items: center; 
  column-gap: 5px;
  color: #8e8e8e; 
  font-size: 13px; 
  font-family: Arial, sans-serif;
}
#goatcounter-footer .statcounter {
  font-family: 'Courier New', monospace; 
  color: var(--gc-counter-color);
  font-weight: bold; 
  margin-left: 3px; 
}
</style>

<!-- GoatCounter Tracker -->
<div id="goatcounter-footer"><span style="margin-left: 3px;">Loading views...</span></div>
<script>
    const path = window.location.pathname;
    console.log('window.location.pathname:', path);
    // If at the root, skip fetching views for now
    if (path.endsWith('index.html') || path.endsWith('/posts/')) {
      
      const display = document.getElementById("goatcounter-footer");
      if (display) {
        display.innerHTML = "";
        console.log("Skipping views for root path:", path);
      }
      
    } else {
      
      // Trim path to remove everything before /quarto_web/site/ for easier local testing
      var trimmedPath = path.replace(/^.*\/posts\//, '\/quarto_web\/site\/posts\/');
      // If the path is exactly /posts/, set trimmedPath to the index.html file
      if (path === '\/posts\/') {
          console.log('Path is exactly /posts/, setting trimmedPath to index.html');
          trimmedPath = '/quarto_web/site/posts/index.html';
      }
      console.log('trimmedPath:', trimmedPath);
      
      // setInterval to check every 100ms because GoatCounter may not be available immediately
      var t = setInterval(function() {
          console.log('Checking for GoatCounter availability...window.goatcounter:', window.goatcounter);
          // Check if GoatCounter is available
          if (window.goatcounter && window.goatcounter.visit_count) {

              // GoatCounter is available, clear the timer
              clearInterval(t)
              // Resolve the counter color to a concrete value
              var footer = document.getElementById('goatcounter-footer');
              var resolvedColor = footer ? getComputedStyle(footer).getPropertyValue('--gc-counter-color').trim() : '';
              console.log('Resolved counter color:', resolvedColor);
              // Update the display with the current visit count
              const display = document.getElementById("goatcounter-footer");
              if (display) {
                display.innerHTML = '<span">Page Views: </span>';
                console.log('display.innerHTML:', display.innerHTML);
              }
              
              
              goatcounter.visit_count({
                no_branding: true,
                path: trimmedPath,
                append: '#goatcounter-footer', 
                style: `
                  body {
                    background: transparent !important;
                  }
                  div { 
                    background: transparent !important;
                    border-width: 0px;
                    border: 0 !important;
                    display: flex;
                  }
                  #gcvc-for {
                    font-size: 0px;
                  }
                  #gcvc-views { 
                      font-family: 'Courier New', monospace; 
                      font-size: 13px;
                      color: ${resolvedColor}; 
                      font-weight: bold; 
                      margin-top: 29px;
                  }`
              })

          }
      }, 100)
      
    }
</script>






<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>