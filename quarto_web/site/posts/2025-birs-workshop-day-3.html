<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-20">
<meta name="description" content="Wednesday, August 20 Â· Day 3 of the 2025 BIRS Workshop â€œFoundation Models and Their Biomedical Applications: Bridging the Gapâ€">

<title>2025 Workshop at BIRS: Day 3 Recordings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#workshop-at-birs-overview" id="toc-workshop-at-birs-overview" class="nav-link active" data-scroll-target="#workshop-at-birs-overview">ğŸ 2025 Workshop at BIRS: Overview</a>
  <ul>
  <li><a href="#foundation-models-and-their-biomedical-applications-bridging-the-gap" id="toc-foundation-models-and-their-biomedical-applications-bridging-the-gap" class="nav-link" data-scroll-target="#foundation-models-and-their-biomedical-applications-bridging-the-gap">Foundation Models and Their Biomedical Applications: Bridging the Gap</a></li>
  </ul></li>
  <li><a href="#day-3-recordings" id="toc-day-3-recordings" class="nav-link" data-scroll-target="#day-3-recordings">â–¶ï¸ Day 3 Recordings</a>
  <ul>
  <li><a href="#talk-sheng-yu-taming-ehrs-for-statistical-readiness-through-large-language-models-and-knowledge-graphs" id="toc-talk-sheng-yu-taming-ehrs-for-statistical-readiness-through-large-language-models-and-knowledge-graphs" class="nav-link" data-scroll-target="#talk-sheng-yu-taming-ehrs-for-statistical-readiness-through-large-language-models-and-knowledge-graphs">ğŸ¤ Sheng Yu: <em>Taming EHRs for Statistical Readiness through Large Language Models and Knowledge Graphs</em></a></li>
  <li><a href="#talk-jian-kang-scalable-bayesian-inference-for-heat-kernel-gaussian-processes-on-manifolds" id="toc-talk-jian-kang-scalable-bayesian-inference-for-heat-kernel-gaussian-processes-on-manifolds" class="nav-link" data-scroll-target="#talk-jian-kang-scalable-bayesian-inference-for-heat-kernel-gaussian-processes-on-manifolds">ğŸ¤ Jian Kang: <em>Scalable Bayesian inference for heat kernel Gaussian processes on manifolds</em></a></li>
  <li><a href="#talk-huaxiu-yao-from-evaluation-to-actionability-closing-factuality-gaps-in-medical-large-visionï¿½language-models" id="toc-talk-huaxiu-yao-from-evaluation-to-actionability-closing-factuality-gaps-in-medical-large-visionï¿½language-models" class="nav-link" data-scroll-target="#talk-huaxiu-yao-from-evaluation-to-actionability-closing-factuality-gaps-in-medical-large-visionï¿½language-models">ğŸ¤ Huaxiu Yao: <em>From Evaluation to Actionability: Closing Factuality Gaps in Medical Large Visionâ€“Language Models</em></a></li>
  <li><a href="#talk-bang-liu-from-recall-to-reason-unlocking-the-cognitive-core-of-foundation-agents" id="toc-talk-bang-liu-from-recall-to-reason-unlocking-the-cognitive-core-of-foundation-agents" class="nav-link" data-scroll-target="#talk-bang-liu-from-recall-to-reason-unlocking-the-cognitive-core-of-foundation-agents">ğŸ¤ Bang Liu: <em>From Recall to Reason: Unlocking the Cognitive Core of Foundation Agents</em></a></li>
  </ul></li>
  <li><a href="#watch-all-recordings" id="toc-watch-all-recordings" class="nav-link" data-scroll-target="#watch-all-recordings">ğŸ“Œ Watch All Recordings</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">2025 Workshop at BIRS: Day 3 Recordings</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Events</div>
    <div class="quarto-category">Videos</div>
  </div>
  </div>

<div>
  <div class="description">
    Wednesday, August 20 Â· Day 3 of the 2025 BIRS Workshop <strong>â€œFoundation Models and Their Biomedical Applications: Bridging the Gapâ€</strong>
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<style>
  .yt-thumb-card{display:flex; align-items:center; justify-content: center; gap:12px;}
  .yt-thumb-card .avatar{width:56px; height:56px; border-radius:50%;}
  .yt-thumb-card .thumb{width:260px; aspect-ratio:16/9; object-fit:cover; border-radius:10px;}
</style>
<!--A minimal thumbnail:-->
<div style="text-align: center; justify-content: center; margin-bottom: 2em;">
<a class="yt-thumb-card" href="https://www.youtube.com/@StatsUpAI" target="_blank"> <img class="avatar" src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj" alt="Stats Up AI" style="width: 20%; height: 20%;"> </a> <a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"> <img src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" alt="Stats Up AI YouTube" width="15%">
<p style="font-size: 14px; margin-top: 0.5em;">
Visit the <strong>Stats Up AI</strong> Channel for More
</p>
</a><p><a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"></a> <!--</div>--></p>
<!--An inline frame (iframe) to embed the YouTube playlist:-->
<!--<div style="text-align: center; margin-top: 1em;">-->
<!--<iframe -->
<!--  max-width="560px"-->
<!--  width="100%"-->
<!--  aspect-ratio="16/9"-->
<!--  src="https://www.youtube.com/embed/videoseries?list=UU2VlJBtA_63CrXP0Sr99P8Q" -->
<!--  title="Uploads playlist"-->
<!--  frameborder="0"-->
<!--  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" -->
<!--  allowfullscreen>-->
<!--</iframe>-->
<!--</div>-->
</div>
<!--YouTube logo:-->
<!--src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" -->
<!--Channel avatar:-->
<!--src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj"-->
<section id="workshop-at-birs-overview" class="level2">
<h2 class="anchored" data-anchor-id="workshop-at-birs-overview">ğŸ 2025 Workshop at BIRS: Overview</h2>
<section id="foundation-models-and-their-biomedical-applications-bridging-the-gap" class="level3">
<h3 class="anchored" data-anchor-id="foundation-models-and-their-biomedical-applications-bridging-the-gap">Foundation Models and Their Biomedical Applications: Bridging the Gap</h3>
<!--**Location:** -->
<p>ğŸ“ Banff International Research Station (BIRS), Banff, Alberta, Canada<br>
<strong>Event Website:</strong> <a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470">2025 Workshop Homepage</a> Â· <strong>Dates:</strong> Aug 17â€“22, 2025<br>
</p>
</section>
</section>
<section id="day-3-recordings" class="level2">
<h2 class="anchored" data-anchor-id="day-3-recordings">â–¶ï¸ Day 3 Recordings</h2>
<section id="talk-sheng-yu-taming-ehrs-for-statistical-readiness-through-large-language-models-and-knowledge-graphs" class="level3">
<h3 class="anchored" data-anchor-id="talk-sheng-yu-taming-ehrs-for-statistical-readiness-through-large-language-models-and-knowledge-graphs">ğŸ¤ Sheng Yu: <em>Taming EHRs for Statistical Readiness through Large Language Models and Knowledge Graphs</em></h3>
<p>ğŸ“… Wednesday, August 20, 2025 â€¢ ğŸ•˜ 08:49 - 09:15<br>
ğŸ›ï¸ Tsinghua University</p>
<strong>Keywords:</strong> clinical text processing, ontology alignment, data standardization<br>

<strong>Summary:</strong> LLMs and knowledge graphs can transform unstructured EHR narratives into standardized, statistically ready data, overcoming the challenges of medical terminology variability in biomedical research data.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Biomedicine has long been one of the
most important application areas of statistics. With the widespread
adoption of electronic health records (EHRs) over the past decade, these
records should, in theory, provide a vast amount of data for analysis.
However, in practice, they remain underutilized, as effectively
extracting information from EHRs is still a challenging and specialized
natural language processing task, due to the substantial medical
knowledge required and the variability of medical terminology. In this
talk, we will briefly review fundamental concepts for analyzing EHRs,
explain the challenges that make EHR analysis difficult, and introduce
how we developed large language models and knowledge graphs to convert
EHR narratives into structured and standardized data ready for
analysisâ€”opening up new frontiers for statistical research and
accelerating progress in biomedicine.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508200849-Yu.mp4" title="BIRS talk: Sheng Yu" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508200849-Yu.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-jian-kang-scalable-bayesian-inference-for-heat-kernel-gaussian-processes-on-manifolds" class="level3">
<h3 class="anchored" data-anchor-id="talk-jian-kang-scalable-bayesian-inference-for-heat-kernel-gaussian-processes-on-manifolds">ğŸ¤ Jian Kang: <em>Scalable Bayesian inference for heat kernel Gaussian processes on manifolds</em></h3>
<p>ğŸ“… Wednesday, August 20, 2025 â€¢ ğŸ•˜ 09:45 - 10:15<br>
ğŸ›ï¸ University of Michigan</p>
<strong>Keywords:</strong> heat kernel methods, manifold regression, neuroimaging analysis<br>

<strong>Summary:</strong> A scalable and general method is proposed for nonparametric regression on manifolds, making it feasible to analyze large neuroimaging datasets and broadly applicable manifold learning problems.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> We introduce a scalable and general
method for nonparametric regression on manifolds, motivated by the
challenge of modeling complex brain activation patterns in large
neuroimaging studies such as the Human Connectome Project (HCP). Our
approach leverages heat kernel techniques to capture the intrinsic
geometric structure of the data and incorporates a novel approximation
strategy that dramatically reduces computational costâ€”-making it
feasible to analyze datasets with thousands of subjects. Although
inspired by neuroimaging applications, the method is broadly applicable
to manifold learning problems across scientific domains. Numerical
experiments demonstrate both its efficiency and accuracy in uncovering
meaningful patterns in high-dimensional, structured data. This is joint
work with Junhui He, Guoxuan Ma, and Ying Yang.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508200945-Kang.mp4" title="BIRS talk: Jian Kang" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508200945-Kang.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-huaxiu-yao-from-evaluation-to-actionability-closing-factuality-gaps-in-medical-large-visionï¿½language-models" class="level3">
<h3 class="anchored" data-anchor-id="talk-huaxiu-yao-from-evaluation-to-actionability-closing-factuality-gaps-in-medical-large-visionï¿½language-models">ğŸ¤ Huaxiu Yao: <em>From Evaluation to Actionability: Closing Factuality Gaps in Medical Large Visionâ€“Language Models</em></h3>
<p>ğŸ“… Wednesday, August 20, 2025 â€¢ ğŸ•˜ 10:33 - 11:05<br>
ğŸ›ï¸ University of North Carolina at Chapel Hill</p>
<strong>Keywords:</strong> factuality evaluation, multimodal preference optimization, retrieval-augmented generation, agent-based reasoning<br>

<strong>Summary:</strong> A layered framework is introduced to improve factual reliability in medical visionâ€“language models, progressing from evaluation benchmarks to clinically grounded alignment, domain-aware retrieval, and agentic reinforcement learning for more trustworthy and actionable clinical decision support.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Medical large visionâ€“language models
(Med-LVLMs) have advanced rapidly, yet their clinical deployment remains
constrained by persistent factuality gaps, especially in high-stakes
settings where even rare hallucinations are unacceptable. This talk
outlines a layered pathway from evaluation to actionability. We begin
with CARES, a benchmark that systematically identifies failure modes in
Med-LVLMs by evaluating deficiencies in factuality, robustness, and
uncertainty estimation. Building on these insights, MMedPO introduces
clinically grounded multimodal preference optimization, enhancing
factual alignment through counterfactual supervision and lesion-aware
training to reduce clinically harmful errors. However, alignment alone
cannot keep pace with evolving medical knowledge. To address this,
MMed-RAG incorporates domain-aware retrieval across modalities and
specialties, employing adaptive context selection and retrieval-guided
pre-tuning to dynamically balance reliance on internal model knowledge
versus external information. For complex clinical scenarios requiring
multi-step reasoning and interdisciplinary collaboration, we present
MMedAgent-RL, which implements a generalist-to-specialist agentic
workflow and uses reinforcement learning to optimize collaborative
decision-making, enabling more faithful and interpretable end-to-end
reasoning. Together, these components form a practical and extensible
framework that improves factual reliability and clinical decision
quality while maintaining transparency. The talk concludes with
strategies for integration and a discussion of open challenges in
scaling this framework to real-world clinical applications.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508201033-Yao.mp4" title="BIRS talk: Huaxiu Yao" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/2025082010333-Yao.html">ğŸ¬Open the video directly</a></p>
</section>
<section id="talk-bang-liu-from-recall-to-reason-unlocking-the-cognitive-core-of-foundation-agents" class="level3">
<h3 class="anchored" data-anchor-id="talk-bang-liu-from-recall-to-reason-unlocking-the-cognitive-core-of-foundation-agents">ğŸ¤ Bang Liu: <em>From Recall to Reason: Unlocking the Cognitive Core of Foundation Agents</em></h3>
<p>ğŸ“… Wednesday, August 20, 2025 â€¢ ğŸ•˜ 11:05 - 11:33<br>
ğŸ›ï¸ University of Montreal</p>
<strong>Keywords:</strong> long-term memory compression, hybrid reasoning, cognitive agent design<br>

<strong>Summary:</strong> This talk presents a cognitive-inspired framework for foundation agents that advances long-term memory and adaptive reasoning, introducing reversible memory compression and hybrid fastâ€“slow reasoning to build scalable, human-aligned agents.<br>

<details>
  <summary><u>ğŸ“– Read more</u></summary>
  <p><strong>Introduction:</strong> Foundation agents, built on the
backbone of large language models, are evolving from passive responders
to active thinkersâ€”autonomously remembering, reasoning, and improving
across tasks and domains. Yet two cognitive capabilities remain crucial
bottlenecks: how they remember and how they think. In this talk, I
present a cognitive-inspired framework for understanding and
architecting foundation agents, with an emphasis on two core
pillarsâ€”memory and reasoningâ€”through the lens of our recent advances. 1)
R3Mem introduces reversible memory compression to balance long-term
retention with precise retrieval, enabling LLM agents to recall extended
histories and interact coherently across long horizons. 2) System-1.5
Reasoning breaks the dichotomy between fast heuristics and slow
deliberation by creating dynamic shortcuts in latent space. It achieves
CoT-level reasoning with up to 20Ã— faster inference, bridging System-1
speed and System-2 depth. These systems pave the way for scalable,
human-aligned foundation agents with enduring memory and adaptive
reasoning. Lastly, Iâ€™ll briefly discuss the scientific significance and
connection with AI agents and statistics.</p>
</details>
<div style="position:relative;padding-top:56.25%;height:0;overflow:hidden;margin:1rem 0;">
  <iframe src="https://videos.birs.ca/2025/25w5470/202508201105-Liu.mp4" title="BIRS talk: Bang Liu" allowfullscreen="" loading="lazy" style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;">
  </iframe>
</div>
<p><a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/202508201105-Liu.html">ğŸ¬Open the video directly</a></p>
<!--Talk Card Template (Blank)-->
<!--::: {.talk-->
<!--speaker="..."-->
<!--title="..."-->
<!--date="Wednesday, August 20, 2025"-->
<!--time="..." -->
<!--org="..." -->
<!--summary="..." -->
<!--keywords="..."-->
<!--video_src="https://videos.birs.ca/2025/25w5470/20250820[].mp4"-->
<!--video_link="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos/watch/20250820[].html"}-->
<!--**Introduction:** -->
<!--...-->
<!--:::-->
</section>
</section>
<section id="watch-all-recordings" class="level2">
<h2 class="anchored" data-anchor-id="watch-all-recordings">ğŸ“Œ Watch All Recordings</h2>
<ul>
<li><strong>StatsUpAI YouTube Channel:</strong> <a href="https://www.youtube.com/@StatsUpAI">Subscribe for updates</a></li>
<li><strong>BIRS Official Videos Page:</strong> <a href="https://www.birs.ca/events/2025/5-day-workshops/25w5470/videos">2025 Workshop Videos</a></li>
<li><strong>Direct Video Downloads:</strong> <a href="https://videos.birs.ca/2025/25w5470/">BIRS Video Server</a></li>
</ul>
<!------->
<style>
  .yt-thumb-card{display:flex; align-items:center; justify-content: center; gap:12px;}
  .yt-thumb-card .avatar{width:56px; height:56px; border-radius:50%;}
  .yt-thumb-card .thumb{width:260px; aspect-ratio:16/9; object-fit:cover; border-radius:10px;}
</style>
<!--A minimal thumbnail:-->
<div style="text-align: center; justify-content: center; margin-bottom: 2em;">
<a class="yt-thumb-card" href="https://www.youtube.com/@StatsUpAI" target="_blank"> <img class="avatar" src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj" alt="Stats Up AI" style="width: 20%; height: 20%;"> </a> <a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"> <img src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" alt="Stats Up AI YouTube" width="15%">
<p style="font-size: 14px; margin-top: 0.5em;">
Visit the <strong>Stats Up AI</strong> Channel for More
</p>
</a><p><a href="https://m.youtube.com/@StatsUpAI/videos?view=0&amp;sort=p&amp;shelf_id=3" target="_blank" style="justify-content: center; margin-bottom: 1em;"></a> <!--</div>--></p>
<!--An inline frame (iframe) to embed the YouTube playlist:-->
<!--<div style="text-align: center; margin-top: 1em;">-->
<!--<iframe -->
<!--  max-width="560px"-->
<!--  width="100%"-->
<!--  aspect-ratio="16/9"-->
<!--  src="https://www.youtube.com/embed/videoseries?list=UU2VlJBtA_63CrXP0Sr99P8Q" -->
<!--  title="Uploads playlist"-->
<!--  frameborder="0"-->
<!--  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" -->
<!--  allowfullscreen>-->
<!--</iframe>-->
<!--</div>-->
</div>
<!--YouTube logo:-->
<!--src="https://www.gstatic.com/youtube/img/branding/youtubelogo/svg/youtubelogo.svg" -->
<!--Channel avatar:-->
<!--src="https://yt3.googleusercontent.com/a9XnyV5aES9fTt4MOMrki6BGphDAUIZpDX1-6uebv03GovLZv4nLcyvgeU00atuLYlVuzEAtKcM=s160-c-k-c0x00ffffff-no-rj"-->
<p><em>AI is rapidly reshaping biomedical research by integrating diverse data, accelerating discovery, and supporting decision-making under uncertainty. With statisticians at the forefront, these applications gain the depth, rigor, and reliability needed to truly transform science and medicine.</em></p>


</section>

</main> <!-- /main -->
<!-- GoatCounter Tracker -->
<script data-goatcounter="https://statsupai.goatcounter.com/count" async="" src="//gc.zgo.at/count.js"></script>

<!-- Per-Page View Counter (Footer Style) -->
<style>
#goatcounter-footer {
  display: flex; 
  align-items: center; 
  color: #8E8E8E; 
  font-size: 13px; 
  font-family: Arial, sans-serif;
}
#goatcounter-footer .statcounter {
  font-family: 'Courier New', monospace; 
  color: #0033cc; 
  font-weight: bold; 
  margin-left: 3px; 
  margin-bottom: -3px;
}
</style>

<div id="goatcounter-footer"><span style="margin-left: 3px;">Loading views...</span></div>
<script>
  // Fetch the page view count from GoatCounter API
  const path = window.location.pathname;
  console.log("Current path:", path);
  // If at the root, skip fetching views for now
  if (path.endsWith('index.html') || path.endsWith('/posts/')) {
    const display = document.getElementById("goatcounter-footer");
    if (display) {
      display.innerHTML = "";
      console.log("Skipping views for root path:", path);
    }
  } else {
    fetch(`https://statsupai.goatcounter.com/api/v0/stats/hits`, {
      headers: { "Authorization": "Bearer auxp85q97cp69ebjpxnwl6po1kaj3megn0nej25li5q72yx3t" }
    })
      .then(res => res.json())
      .then(data => {
        const display = document.getElementById("goatcounter-footer");
        if (display) {
          // API response is an array of hits per path
          // Trim path to remove everything before /quarto_web/site/ for easier local testing
          const trimmedPath = path.replace(/^.*\/posts\//, '\/quarto_web\/site\/posts\/');
          // From the array data.hits, filter out the hits for the current path
          const hit = data.hits.find(hit => hit.path === trimmedPath);
          // If hit is found, get the count, otherwise default to 0
          const views = hit.count || 0;
          display.innerHTML = `
            <span>Page Views:
            <span class='statcounter'> ${views}</span></span>
          `;
  
          // Debugging log (optional)
          console.log("Display updated with views:", views);
        }
      })
      .catch(() => {
        const display = document.getElementById("goatcounter-footer");
        if (display) display.innerHTML = "Page views unavailable. Try again later.";
      });
  }
  
  
</script>

<!--<div style="display: flex; align-items: center; color: #8E8E8E; font-size: 13px; font-family: Arial, sans-serif;">-->
<!--Page Views:-->
<!--<div class="statcounter" style="margin-left: 10px;">-->
<!-- Default Statcounter code for seminar1
<!--https://statsupai.org/quarto_web/site/posts/StatsUP-AI%20Statistical%20and%20AI%20Methods%20for%20He-->
<!---->
<!--<script type="text/javascript">-->
<!--var sc_project=13110735; -->
<!--var sc_invisible=0; -->
<!--var sc_security="92556aa5"; -->
<!--var scJsHost = "https://";-->
<!--document.write("<sc"+"ript type='text/javascript' src='" +-->
<!--scJsHost+-->
<!--"statcounter.com/counter/counter.js'></"+"script>");-->
<!--</script>-->
<!--<noscript>-->
<!--<div class="statcounter">-->
<!--<a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img class="statcounter" src="https://c.statcounter.com/13110735/0/92556aa5/0/" alt="Web Analytics" referrerpolicy="no-referrer-when-downgrade"></a>-->
<!--</div>-->
<!--</noscript>-->
<!-- End of Statcounter Code -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>