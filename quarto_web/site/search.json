[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto_web",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "",
    "section": "",
    "text": "Stats Up AI Pioneer Papers (Dr. Pei Wang)\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nThe Large-scale Neuroimaging-related Studies Directory\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/4covid.html",
    "href": "research/4covid.html",
    "title": "Bayesian Learning of COVID-19 Vaccine Safety",
    "section": "",
    "text": "In the COVID-19 pandemic, as a researcher at the University of Michigan, I embarked on a project that stood at the intersection of public health urgency and statistical innovation. My work, titled “Bayesian Learning of COVID-19 Vaccine Safety,” was driven by a critical need: to bolster public confidence in the rapidly developed COVID-19 vaccines.\nWe focus on the Vaccine Adverse Event Reporting System (VAERS), a database with a large number of reports, but with noise and potential over-reporting issues. Recognizing the intricate relationships between different adverse events (AEs), I realized that existing statistical methods fell short in capturing this complexity. It was here that the idea for the Bayesian graph-assisted signal selection (BGrass) model took root.\nBGrass was a pioneering approach, the first of its kind to integrate AE ontology into vaccine-AE disproportionality analyses. The model wasn’t just another statistical tool; it was a novel lens through which the interconnected web of AEs could be viewed and understood. With BGrass, we could simultaneously evaluate the risk of all AEs while acknowledging their interdependencies under a logistic regression framework.\n\nOne of the most challenging aspects was mitigating reporting bias. To address this, I proposed a negative control approach, coupled with an enrichment method to pinpoint AE groups warranting attention. The computational backbone of BGrass was an efficient Gibbs sampler, utilizing Pólya-gamma data augmentation — a method I meticulously developed and made accessible through an R package.\nBut what did all this mean in practical terms? By applying BGrass to over a million VAERS reports, we weren’t just crunching numbers; we were identifying real signals amid the cacophony of data. We pinpointed eight AEs specifically related to COVID-19 vaccines, enhancing our understanding of post-vaccination safety. The accuracy of our estimations of log-odds ratios improved significantly — by up to 35% when abundant ontology information was available.\nThis journey with BGrass was more than a research project; it was a testament to the power of statistical ingenuity in addressing pressing public health challenges. As the world grappled with the uncertainties of a new disease and its vaccines, our work offered a beacon of clarity, contributing to the global effort to ensure vaccine safety and ultimately, to restore public trust in these life-saving tools."
  },
  {
    "objectID": "research/2gomoku.html",
    "href": "research/2gomoku.html",
    "title": "Mastering the Game of Gomoku with Deep Neural Networks",
    "section": "",
    "text": "In this project, I’ve implemented Monte Carlo Tree Search (MCTS) in a simplified version of the game Gomoku, coupled with an image-to-image prediction neural network to guide the tree-search. This venture into machine learning was inspired by my interest in Chinese Go and the great work of Google’s AlphaGo in 2016.\nDiscover more about this project on my Github, or experience the game through this online link. I developed the game’s GUI using Pygame, creating a lightweight HTML version that performs a limited number of simulations per move for a more accessible gaming experience."
  },
  {
    "objectID": "research/1bci.html",
    "href": "research/1bci.html",
    "title": "Stats Up AI Pioneer Papers (Dr. Pei Wang)",
    "section": "",
    "text": "Unveiling Immunity Across Cancers: An Interview with Dr. Pei Wang on Her Groundbreaking Research\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n\n    \n    \n    \n        Dr. Pei Wang\n        Dr. Pei Wang is a Professor of Genetic and Genomic Sciences at Icahn School of Medicine at Mount Sinai, New York. She obtained her B.S. in Mathematics from Peking University, China, in 2000; and her Ph.D. in Statistics from Stanford University in 2004. Between 2004-2013, Dr. Wang held faculty positions in the Program of Biostatistics at Fred Hutchinson Cancer Research Center and the Department of Biostatistics at the University of Washington, Seattle, WA. In Oct 2013, Dr. Wang joint Icahn Medical School at Mount Sinai, New York.\n        Dr. Wang's research is dedicated to advancing statistical and computational methodologies, translating vast datasets related to diseases such as cancer into meaningful insights to help with patient treatment. She serves as the Principal Investigator of the NCI Clinical Proteomic Tumor Analysis Consortium (CPTAC), focusing on unraveling the molecular underpinnings of cancer through extensive proteome and genome analyses. Leading the CPTAC Proteogenomics Data Analysis Center at Mount Sinai, Dr. Wang's team strives to identify potential biomarkers and drug targets for cancer, thereby accelerating progress in cancer research.\n        \n    \n\n    \n    The Article Link:Pan-cancer Proteogenomics Characterization of Tumor Immunity\n    \n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        Dr. Pei Wang: This work discovered new knowledge. \n        In our paper “Pan-Cancer Proteogenomics Characterization of Tumor Immunity” (Cell, 2024, Feb, PMID: 38359819), we integrated DNA, RNA, and proteomics data derived from more than 1,000 tumors across 10 different cancers to reveal the complex interplay of immune and tumor cells. The data came from the Clinical Proteomic Tumor Analysis Consortium (CPTAC), a program under the National Cancer Institute. \n        This work aimed to improve our understanding of the mechanisms underlying the functional impairment of immune response in tumors. By closely examining genes and proteins in the tumor tissues, we discovered various patterns in immune activation and suppression, and unraveled diverse immune subtypes. \n        \n\n        How did the reviewers evaluate (praise) it?\n        Dr. Pei Wang: The reviewers described the study “current, highly impactful and well developed” with “technical rigor in its methodology and data analysis”, and suggesting that “the key findings advance our understanding of the immune landscape in various cancers and provide potential targets for therapeutic interventions”.\n        \n        If thisachievement has potential applications, what are some specific applications it might have in a few years?\n        Dr. Pei Wang: The findings from the paper can help clinicians to identify patient groups more responsive to immunotherapy. Revealing the specific pathways and cellular switches for each subtype can also spark new and creative ways to develop treatments. For example we nominated a set of kinases that are potential targets for converting cold tumors into hot tumors, thus enhancing their responsiveness to immune-based treatments. We hope some of those leads can be investigated further and be carried out into clinical trials in the future.\n        \n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        Dr. Pei Wang: I have been leading a data analysis center for NCI Clinical Proteomics Tumor Analysis Consortium (CPTAC) in the past 8 years. Throughout this period, the CPTAC consortium has generated an extensive collection of large-scale, deep proteogenomics data sets. This invaluable resource has offered us a unique opportunity to conduct, for the first time, large-scale (with &gt;1000 tumor samples) proteogenomic analyses to understand the immune landscape across 10 cancer types. Especially, the pan-cancer phosphoproteomics data enables us to comprehensively characterize the kinase activities relating to different immune activation and evasion patterns in tumor samples. This aspect, which has not been extensively explored in prior genomics studies, significantly enhances our understanding of the immune landscape in cancer.\n\n        In this study, unlocking meaningful biological signals from the vast sea of data required meticulous attention to comprehensive data preprocessing, encompassing quality control and harmonization. Employing sophisticated statistical modeling and rigorous inference techniques is also vital to ensure the extraction of genuine and relevant biological insights. Over the course of more than a year, consortium members, comprising multiple teams from different institutions, collaborated to meticulously assemble, quality-check, and harmonize datasets from various CPTAC cancer studies. Confronting challenges inherent in data analysis, we also undertook the development and enhancement of multiple data analysis pipelines to optimize the analytical process.\n        Another important component for the success of the study is that we are able to work very closely with pathologists and clinicians to interpret the results and obtain additional experiment evidence to validate the data analysis results. It’s truly a team work of researchers from different disciplines. \n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        Dr. Pei Wang: Unforgettable moments unfolded when unexpected and significant findings emerged from the study. Out of the seven identified subtypes, five encompassed tumors from 10 distinct cancer types, suggesting shared immune responses across these tumors. Additionally, we noted similar kinase activation patterns across different cancers within the same immune subtype. This implies the potential applicability of specific immunotherapy treatments to a broad spectrum of cancer types.                                   \n        Another surprising finding is that, in one subtype (CD8-IFNG+), despite high activity in the IFNG pathway, there was a surprising observation of low immune cell infiltration. This is unexpected, as an active IFNG pathway is typically associated with a robust immune response. Alternative treatment will be needed for this group of patients compared to those from CD8+IFNG+.\n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        Dr. Pei Wang: We are seeking opportunities to validate our findings through the analysis of cellular level proteomic/transcriptomic data from cutting-edge single-cell platforms. Furthermore, we intend to leverage the insights garnered from this paper in other clinical studies focused on immunotherapy treatment. This effort aims to streamline the development of biomarker panels for treatment responses and identify enhanced treatment strategies. To exemplify, in collaboration with other CPTAC scientists, I am actively involved in a proteogenomic study aimed at unraveling the intricate molecular mechanisms that underlie responses to immune checkpoint treatments in melanoma patients.\n        \n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        Dr. Pei Wang: I don’t think our work relating to “AI” --- which, in my opinion, involves “self-learning” at real time. But this is definitely a work of BIG data. I believe statisticians play a pivotal role at the forefront, leveraging data to enhance our understanding across a myriad of fields. \n        \n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n        Dr. Pei Wang: One challenge in cancer research is the extensive sample heterogeneity, both within and across different cancers. With the CPTAC Pan Cancer cohort (&gt;1000), we were more powered to reveal unique subtypes not detected in individual cancer studies. Nevertheless, we may not exhaustively identify every potential immune subtype present in these tumors. Also, tumors may exhibit a spectrum of immune infiltration that defies easy categorization into discrete subtypes.\n        \n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "research/3als.html",
    "href": "research/3als.html",
    "title": "Peripheral immune profiles predict ALS progression",
    "section": "",
    "text": "As a Research Assistant at the ALS Center of Excellence, University of Michigan, I’ve involved in a fascinating study of Amyotrophic Lateral Sclerosis (ALS). My project focuses on how peripheral immune profiles can predict the progression of ALS, measured by the ALS Functional Rating Scale-Revised (ALSFRS-R) score.\nIn collaboration with esteemed neurology experts, I applied unsupervised hierarchical clustering and LASSO-Cox regression models to the clinical dataset. These sophisticated statistical tools, often reserved for the realms of high-end data science, allowed us to unearth patterns that were not immediately apparent. My work wasn’t just about numbers and models. It was about translating these complex findings into a format that could be easily understood by the broader medical community, including those without a statistical background. Using ggplot2, a tool in R for data visualization, I crafted aesthetically pleasing and informative visuals. The implications of this study are profound. By identifying key biomarkers, we’ve taken a significant step towards enhancing the precision of prognostic models for ALS."
  },
  {
    "objectID": "research/old_files/neuroimaging.html",
    "href": "research/old_files/neuroimaging.html",
    "title": "The Large-scale Neuroimaging-related Studies Directory",
    "section": "",
    "text": "This is online resource that provides succinct overviews and direct access to pivotal neuroimaging research. Aimed at researchers, academics, and enthusiasts, the directory compiles key studies exploring brain structure, function, and neurological disease progression. It stands as a hub for fostering collaboration, enhancing data transparency, and promoting scientific advancements in the field of neuroimaging.\n\n\n\nName\nDescription\nWebsite\n\n\n\n\nAlzheimer’s Disease Neuroimaging Initiative (ADNI)\nA multisite, longitudinal study aimed at validating biomarkers for Alzheimer’s disease (AD) clinical trials, tracking AD progression through clinical, imaging, genetic, and biospecimen markers across various stages from normal aging to dementia.\nADNI\n\n\nConnectome Coordination Facility (CCF)\nHouses and distributes public research data for a series of studies that focus on the connections within the human brain, known as Human Connectome Projects.\nCCF\n\n\nHuman Connectome Project (HCP)\nGathers data from 1,200 healthy young adults to create a comprehensive “network map” of the healthy human brain, exploring individual variability in brain circuits.\nHCP\n\n\nUK Biobank (UKB)\nA large-scale biomedical database and research resource containing de-identified genetic, lifestyle and health information, and biological samples from half a million UK participants.\nUKB\n\n\nAdolescent Brain Cognitive Development Study (ABCD)\nThe largest long-term research project in the United States focusing on brain development and child health, inviting 11,880 children aged 9-10 to participate.\nABCD\n\n\nEnhancing NeuroImaging Genetics through Meta-Analysis (ENIGMA)\nBrings together researchers in imaging genomics to understand brain structure, function, and disease, based on brain imaging and genetic data.\nENIGMA\n\n\nAll of Us Research Program\nA research program from the National Institutes of Health (NIH) aims to enroll one million or more people from across the U.S. to advance medical research.\nAll of Us\n\n\nOsteoarthritis Initiative (OAI)\nA multi-center, ten-year observational study involving men and women, aimed at providing resources to enhance the understanding of prevention and treatment of knee osteoarthritis.\nOAI\n\n\nPhiladelphia Neurodevelopmental Cohort (PNC)\nCenters on exploring the interplay between brain, behavior, and genetics, involving over 9,500 individuals from the greater Philadelphia area.\nPNC\n\n\nPediatric Imaging, Neurocognition, and Genetics (PING)\nA large repository of standardized measurements of behavioral and imaging phenotypes accompanied by whole genome genotyping acquired from typically-developing children.\nPING\n\n\nNational Lung Screening Trial (NLST)\nA randomized multicenter study comparing low-dose helical computed tomography (CT) with chest radiography in the screening of older current and former heavy smokers for early detection of lung cancer.\nNLST\n\n\nImage & Data Archive (IDA)\nOffers tools for de-identification, integration, search, visualization, and sharing diverse neuroscience data.\nIDA\n\n\nNIMH Data Archive (NDA)\nOffers an infrastructure that makes available human subjects data from hundreds of research projects across various scientific domains.\nNDA\n\n\nBrain Image Library (BIL)\nA national public resource providing facilities for depositing, analyzing, sharing, and interacting with large brain image datasets.\nBIL\n\n\nProstate, Lung, Colorectal, and Ovarian Cancer Screening Trial (PLCO)\nA randomized, controlled trial conducted to determine if specific screening exams reduce mortality from these cancers, enrolling approximately 155,000 participants.\nPLCO\n\n\nNeuroImaging Tools & Resources Collaboratory (NITRC)\nA free web-based resource that offers comprehensive information on neuroinformatics software and data.\nNITRC\n\n\nThe Cancer Genome Atlas (TCGA)\nA comprehensive effort to accelerate our understanding of the molecular basis of cancer through genome analysis technologies.\nTCGA\n\n\nBrain Tumor Segmentation (BraTS) Challenge\nSince 2012, BraTS has focused on the generation of a benchmarking environment and dataset for the delineation of adult brain gliomas.\nBraTS"
  },
  {
    "objectID": "posts/interview_peiwang.html",
    "href": "posts/interview_peiwang.html",
    "title": "Unveiling Immunity Across Cancers: An Interview with Dr. Pei Wang",
    "section": "",
    "text": "Unveiling Immunity Across Cancers: An Interview with Dr. Pei Wang on Her Groundbreaking Research\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n\n    \n    \n    \n        Dr. Pei Wang\n        Dr. Pei Wang is a Professor of Genetic and Genomic Sciences at Icahn School of Medicine at Mount Sinai, New York. She obtained her B.S. in Mathematics from Peking University, China, in 2000; and her Ph.D. in Statistics from Stanford University in 2004. Between 2004-2013, Dr. Wang held faculty positions in the Program of Biostatistics at Fred Hutchinson Cancer Research Center and the Department of Biostatistics at the University of Washington, Seattle, WA. In Oct 2013, Dr. Wang joint Icahn Medical School at Mount Sinai, New York.\n        Dr. Wang's research is dedicated to advancing statistical and computational methodologies, translating vast datasets related to diseases such as cancer into meaningful insights to help with patient treatment. She serves as the Principal Investigator of the NCI Clinical Proteomic Tumor Analysis Consortium (CPTAC), focusing on unraveling the molecular underpinnings of cancer through extensive proteome and genome analyses. Leading the CPTAC Proteogenomics Data Analysis Center at Mount Sinai, Dr. Wang's team strives to identify potential biomarkers and drug targets for cancer, thereby accelerating progress in cancer research.\n        \n    \n\n    \n    The Article Link:Pan-cancer Proteogenomics Characterization of Tumor Immunity\n    \n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        Dr. Pei Wang: This work discovered new knowledge. \n        In our paper “Pan-Cancer Proteogenomics Characterization of Tumor Immunity” (Cell, 2024, Feb, PMID: 38359819), we integrated DNA, RNA, and proteomics data derived from more than 1,000 tumors across 10 different cancers to reveal the complex interplay of immune and tumor cells. The data came from the Clinical Proteomic Tumor Analysis Consortium (CPTAC), a program under the National Cancer Institute. \n        This work aimed to improve our understanding of the mechanisms underlying the functional impairment of immune response in tumors. By closely examining genes and proteins in the tumor tissues, we discovered various patterns in immune activation and suppression, and unraveled diverse immune subtypes. \n        \n\n        How did the reviewers evaluate (praise) it?\n        Dr. Pei Wang: The reviewers described the study “current, highly impactful and well developed” with “technical rigor in its methodology and data analysis”, and suggesting that “the key findings advance our understanding of the immune landscape in various cancers and provide potential targets for therapeutic interventions”.\n        \n        If thisachievement has potential applications, what are some specific applications it might have in a few years?\n        Dr. Pei Wang: The findings from the paper can help clinicians to identify patient groups more responsive to immunotherapy. Revealing the specific pathways and cellular switches for each subtype can also spark new and creative ways to develop treatments. For example we nominated a set of kinases that are potential targets for converting cold tumors into hot tumors, thus enhancing their responsiveness to immune-based treatments. We hope some of those leads can be investigated further and be carried out into clinical trials in the future.\n        \n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        Dr. Pei Wang: I have been leading a data analysis center for NCI Clinical Proteomics Tumor Analysis Consortium (CPTAC) in the past 8 years. Throughout this period, the CPTAC consortium has generated an extensive collection of large-scale, deep proteogenomics data sets. This invaluable resource has offered us a unique opportunity to conduct, for the first time, large-scale (with &gt;1000 tumor samples) proteogenomic analyses to understand the immune landscape across 10 cancer types. Especially, the pan-cancer phosphoproteomics data enables us to comprehensively characterize the kinase activities relating to different immune activation and evasion patterns in tumor samples. This aspect, which has not been extensively explored in prior genomics studies, significantly enhances our understanding of the immune landscape in cancer.\n\n        In this study, unlocking meaningful biological signals from the vast sea of data required meticulous attention to comprehensive data preprocessing, encompassing quality control and harmonization. Employing sophisticated statistical modeling and rigorous inference techniques is also vital to ensure the extraction of genuine and relevant biological insights. Over the course of more than a year, consortium members, comprising multiple teams from different institutions, collaborated to meticulously assemble, quality-check, and harmonize datasets from various CPTAC cancer studies. Confronting challenges inherent in data analysis, we also undertook the development and enhancement of multiple data analysis pipelines to optimize the analytical process.\n        Another important component for the success of the study is that we are able to work very closely with pathologists and clinicians to interpret the results and obtain additional experiment evidence to validate the data analysis results. It’s truly a team work of researchers from different disciplines. \n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        Dr. Pei Wang: Unforgettable moments unfolded when unexpected and significant findings emerged from the study. Out of the seven identified subtypes, five encompassed tumors from 10 distinct cancer types, suggesting shared immune responses across these tumors. Additionally, we noted similar kinase activation patterns across different cancers within the same immune subtype. This implies the potential applicability of specific immunotherapy treatments to a broad spectrum of cancer types.                                   \n        Another surprising finding is that, in one subtype (CD8-IFNG+), despite high activity in the IFNG pathway, there was a surprising observation of low immune cell infiltration. This is unexpected, as an active IFNG pathway is typically associated with a robust immune response. Alternative treatment will be needed for this group of patients compared to those from CD8+IFNG+.\n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        Dr. Pei Wang: We are seeking opportunities to validate our findings through the analysis of cellular level proteomic/transcriptomic data from cutting-edge single-cell platforms. Furthermore, we intend to leverage the insights garnered from this paper in other clinical studies focused on immunotherapy treatment. This effort aims to streamline the development of biomarker panels for treatment responses and identify enhanced treatment strategies. To exemplify, in collaboration with other CPTAC scientists, I am actively involved in a proteogenomic study aimed at unraveling the intricate molecular mechanisms that underlie responses to immune checkpoint treatments in melanoma patients.\n        \n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        Dr. Pei Wang: I don’t think our work relating to “AI” --- which, in my opinion, involves “self-learning” at real time. But this is definitely a work of BIG data. I believe statisticians play a pivotal role at the forefront, leveraging data to enhance our understanding across a myriad of fields. \n        \n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n        Dr. Pei Wang: One challenge in cancer research is the extensive sample heterogeneity, both within and across different cancers. With the CPTAC Pan Cancer cohort (&gt;1000), we were more powered to reveal unique subtypes not detected in individual cancer studies. Nevertheless, we may not exhaustively identify every potential immune subtype present in these tumors. Also, tumors may exhibit a spectrum of immune infiltration that defies easy categorization into discrete subtypes.\n        \n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "conducting_research_with_UK_biobank.html",
    "href": "conducting_research_with_UK_biobank.html",
    "title": "Conducting research with UK biobank",
    "section": "",
    "text": "Conducting research with UK biobank"
  },
  {
    "objectID": "posts/Conducting_research_with_All_of_Us.html",
    "href": "posts/Conducting_research_with_All_of_Us.html",
    "title": "Conducting research with All of Us",
    "section": "",
    "text": "Introduction video is here!"
  },
  {
    "objectID": "posts/template.html",
    "href": "posts/template.html",
    "title": "Townhall meeting on the role of statisticians for the future of AI",
    "section": "",
    "text": "Feb 7 4:30 pm EST (meeting slides,  recording)"
  },
  {
    "objectID": "posts/Townhall meeting.html",
    "href": "posts/Townhall meeting.html",
    "title": "Townhall meeting on the role of statisticians for the future of AI",
    "section": "",
    "text": "Feb 7 4:30 pm EST (meeting slides,  recording)"
  },
  {
    "objectID": "posts/Statistics for the Future of AI.html",
    "href": "posts/Statistics for the Future of AI.html",
    "title": "Statistics for the Future of AI",
    "section": "",
    "text": "Dear Fellow Statisticians,\nThe emergence of artificial intelligence (AI) has significantly transformed our society, highlighting the critical role of our discipline in AI’s evolution. Our expertise in statistics is integral to developing robust designs, models, and algorithms that shape AI.\nWe are excited to share with you\n&gt; \n                                        \nThe Youtube playlist from a recent research retreat workshop “Statistics for the Future of AI,” an esteemed event sponsored by the Mohammed Bin Zayed University of Artificial Intelligence. This playlist features insightful keynote presentations from distinguished statisticians Hongtu Zhu, Xihong Lin, Tianxi Cai, and Susan Murphy. Their talks focus on the vital role of statistics and statisticians in advancing AI research, particularly in the realm of healthcare. Additionally, the playlist includes 14 lightning talks by other eminent statisticians who participated in the workshop. These discussions highlight the pressing challenges in AI and healthcare, emphasizing the need for innovative statistical solutions and the significant contributions statisticians can bring to this field. We encourage you to explore these presentations to gain a deeper understanding of the dynamic interplay between AI and healthcare and the central role of statistics in this evolving landscape. Your engagement and insights are invaluable as we strive to more seamlessly integrate statistics with AI. Let’s continue to foster discussions about “Statistics Up AI” within our community and collectively and proactively advance our research paradigms to embrace the opportunities AI presents.\nMost videos are quite interesting, since we asked each speaker to focus on the following questions.\n[Prediction] - what would be the next stage for research in this field for the next 5-10 years?\n[Vision] What would be the most exciting and pivotal breakthrough that AI and Statistics could lead to that will change the practice?\n[Position] What is the most important open question that the research community is grappling with?\n[Position] How could an individual statistician get started to contribute? What could a team/department do collectively to accelerate progress?\nAll speakers gave their honest opinions about the future of statistics in the AI era.\nIt is very good for students and faculty members.\nTian Zheng, Professor and Chair, Department of Statistics, Columbia University\nHongtu Zhu, Professor, Department of Biostatistics, The University of North Carolina at Chapel Hill"
  },
  {
    "objectID": "posts/Statistics for the Future of AI - Copy.html",
    "href": "posts/Statistics for the Future of AI - Copy.html",
    "title": "Journal of Data Science calls for contributions to a special issue on the same topic",
    "section": "",
    "text": "The Journal of Data Science (JDS) invites submissions for a special issue on “Statistical Aspects of Trustworthy Machine Learning.” This special issue aims to showcase the state-of-the-art advancements in statistical aspects of machine learning's interpretability, fairness, transparency, and robustness. We invite submissions addressing statistical solutions to trust challenges in diverse machine learning applications.(click here for more info)."
  },
  {
    "objectID": "posts/Statistics for the Future of AI - Copy (4).html",
    "href": "posts/Statistics for the Future of AI - Copy (4).html",
    "title": "Statistics for the Future of AI",
    "section": "",
    "text": "Dear Fellow Statisticians,\nThe emergence of artificial intelligence (AI) has significantly transformed our society, highlighting the critical role of our discipline in AI’s evolution. Our expertise in statistics is integral to developing robust designs, models, and algorithms that shape AI.\nWe are excited to share with you\n&gt; \n                                        \nThe Youtube playlist from a recent research retreat workshop “Statistics for the Future of AI,” an esteemed event sponsored by the Mohammed Bin Zayed University of Artificial Intelligence. This playlist features insightful keynote presentations from distinguished statisticians Hongtu Zhu, Xihong Lin, Tianxi Cai, and Susan Murphy. Their talks focus on the vital role of statistics and statisticians in advancing AI research, particularly in the realm of healthcare. Additionally, the playlist includes 14 lightning talks by other eminent statisticians who participated in the workshop. These discussions highlight the pressing challenges in AI and healthcare, emphasizing the need for innovative statistical solutions and the significant contributions statisticians can bring to this field. We encourage you to explore these presentations to gain a deeper understanding of the dynamic interplay between AI and healthcare and the central role of statistics in this evolving landscape. Your engagement and insights are invaluable as we strive to more seamlessly integrate statistics with AI. Let’s continue to foster discussions about “Statistics Up AI” within our community and collectively and proactively advance our research paradigms to embrace the opportunities AI presents.\nMost videos are quite interesting, since we asked each speaker to focus on the following questions.\n[Prediction] - what would be the next stage for research in this field for the next 5-10 years?\n[Vision] What would be the most exciting and pivotal breakthrough that AI and Statistics could lead to that will change the practice?\n[Position] What is the most important open question that the research community is grappling with?\n[Position] How could an individual statistician get started to contribute? What could a team/department do collectively to accelerate progress?\nAll speakers gave their honest opinions about the future of statistics in the AI era.\nIt is very good for students and faculty members.\nTian Zheng, Professor and Chair, Department of Statistics, Columbia University\nHongtu Zhu, Professor, Department of Biostatistics, The University of North Carolina at Chapel Hill"
  },
  {
    "objectID": "posts/Statistics for the Future of AI - Copy (2).html",
    "href": "posts/Statistics for the Future of AI - Copy (2).html",
    "title": "Statistics for the Future of AI",
    "section": "",
    "text": "Dear Fellow Statisticians,\nThe emergence of artificial intelligence (AI) has significantly transformed our society, highlighting the critical role of our discipline in AI’s evolution. Our expertise in statistics is integral to developing robust designs, models, and algorithms that shape AI.\nWe are excited to share with you\n&gt; \n                                        \nThe Youtube playlist from a recent research retreat workshop “Statistics for the Future of AI,” an esteemed event sponsored by the Mohammed Bin Zayed University of Artificial Intelligence. This playlist features insightful keynote presentations from distinguished statisticians Hongtu Zhu, Xihong Lin, Tianxi Cai, and Susan Murphy. Their talks focus on the vital role of statistics and statisticians in advancing AI research, particularly in the realm of healthcare. Additionally, the playlist includes 14 lightning talks by other eminent statisticians who participated in the workshop. These discussions highlight the pressing challenges in AI and healthcare, emphasizing the need for innovative statistical solutions and the significant contributions statisticians can bring to this field. We encourage you to explore these presentations to gain a deeper understanding of the dynamic interplay between AI and healthcare and the central role of statistics in this evolving landscape. Your engagement and insights are invaluable as we strive to more seamlessly integrate statistics with AI. Let’s continue to foster discussions about “Statistics Up AI” within our community and collectively and proactively advance our research paradigms to embrace the opportunities AI presents.\nMost videos are quite interesting, since we asked each speaker to focus on the following questions.\n[Prediction] - what would be the next stage for research in this field for the next 5-10 years?\n[Vision] What would be the most exciting and pivotal breakthrough that AI and Statistics could lead to that will change the practice?\n[Position] What is the most important open question that the research community is grappling with?\n[Position] How could an individual statistician get started to contribute? What could a team/department do collectively to accelerate progress?\nAll speakers gave their honest opinions about the future of statistics in the AI era.\nIt is very good for students and faculty members.\nTian Zheng, Professor and Chair, Department of Statistics, Columbia University\nHongtu Zhu, Professor, Department of Biostatistics, The University of North Carolina at Chapel Hill"
  },
  {
    "objectID": "posts/Statistics for the Future of AI - Copy (3).html",
    "href": "posts/Statistics for the Future of AI - Copy (3).html",
    "title": "Statistics for the Future of AI",
    "section": "",
    "text": "Dear Fellow Statisticians,\nThe emergence of artificial intelligence (AI) has significantly transformed our society, highlighting the critical role of our discipline in AI’s evolution. Our expertise in statistics is integral to developing robust designs, models, and algorithms that shape AI.\nWe are excited to share with you\n&gt; \n                                        \nThe Youtube playlist from a recent research retreat workshop “Statistics for the Future of AI,” an esteemed event sponsored by the Mohammed Bin Zayed University of Artificial Intelligence. This playlist features insightful keynote presentations from distinguished statisticians Hongtu Zhu, Xihong Lin, Tianxi Cai, and Susan Murphy. Their talks focus on the vital role of statistics and statisticians in advancing AI research, particularly in the realm of healthcare. Additionally, the playlist includes 14 lightning talks by other eminent statisticians who participated in the workshop. These discussions highlight the pressing challenges in AI and healthcare, emphasizing the need for innovative statistical solutions and the significant contributions statisticians can bring to this field. We encourage you to explore these presentations to gain a deeper understanding of the dynamic interplay between AI and healthcare and the central role of statistics in this evolving landscape. Your engagement and insights are invaluable as we strive to more seamlessly integrate statistics with AI. Let’s continue to foster discussions about “Statistics Up AI” within our community and collectively and proactively advance our research paradigms to embrace the opportunities AI presents.\nMost videos are quite interesting, since we asked each speaker to focus on the following questions.\n[Prediction] - what would be the next stage for research in this field for the next 5-10 years?\n[Vision] What would be the most exciting and pivotal breakthrough that AI and Statistics could lead to that will change the practice?\n[Position] What is the most important open question that the research community is grappling with?\n[Position] How could an individual statistician get started to contribute? What could a team/department do collectively to accelerate progress?\nAll speakers gave their honest opinions about the future of statistics in the AI era.\nIt is very good for students and faculty members.\nTian Zheng, Professor and Chair, Department of Statistics, Columbia University\nHongtu Zhu, Professor, Department of Biostatistics, The University of North Carolina at Chapel Hill"
  },
  {
    "objectID": "posts/Journal of Data Science.html",
    "href": "posts/Journal of Data Science.html",
    "title": "Journal of Data Science calls for contributions to a special issue on the same topic",
    "section": "",
    "text": "The Journal of Data Science (JDS) invites submissions for a special issue on “Statistical Aspects of Trustworthy Machine Learning.” This special issue aims to showcase the state-of-the-art advancements in statistical aspects of machine learning's interpretability, fairness, transparency, and robustness. We invite submissions addressing statistical solutions to trust challenges in diverse machine learning applications.(click here for more info)."
  },
  {
    "objectID": "posts/conducting_research_with_UK_biobank - Copy.html",
    "href": "posts/conducting_research_with_UK_biobank - Copy.html",
    "title": "Call proposal for JASA special issue on AI",
    "section": "",
    "text": "We are excited to announce a call for papers for a special issue dedicated to exploring the intersection of statistical theory, and methods and applications with core problems in Artificial Intelligence (AI). This issue aims to map the evolving landscape of innovative statistical research inspired and motivated by the rapid developments in AI, and to pioneer integrated statistical AI methods to advance scientific discovery and trustworthy AI (click here for more info)."
  },
  {
    "objectID": "posts/Statistical Aspects of Trustworthy Machine Learning.html",
    "href": "posts/Statistical Aspects of Trustworthy Machine Learning.html",
    "title": "Statistical Aspects of Trustworthy Machine Learning",
    "section": "",
    "text": "Beginning on Sunday, February 11 and ending Friday February 16, 2024 \n                            A list of workshop videos are posted here!"
  },
  {
    "objectID": "posts/Data and AI Intensive Research.html",
    "href": "posts/Data and AI Intensive Research.html",
    "title": "Data and AI Intensive Research with Rigor and Reproducibility (DAIR³)",
    "section": "",
    "text": "Applications now open for the 2024 cohort\n                            The Data and AI Intensive Research with Rigor and Reproducibility (DAIR3) program includes weeklong bootcamps in the summer that focus on ethical issues in biomedical data science; data management, representation, and sharing; rigorous analytical design; the design and reporting of AI models; generative AI; reproducible workflow; and assessing findings across studies. Additionally, the bootcamp also includes grant writing sessions and research collaboration discussions. (click here for more info)"
  },
  {
    "objectID": "posts/Call proposal for JASA special issue on AI.html",
    "href": "posts/Call proposal for JASA special issue on AI.html",
    "title": "Call proposal for JASA special issue on AI",
    "section": "",
    "text": "We are excited to announce a call for papers for a special issue dedicated to exploring the intersection of statistical theory, and methods and applications with core problems in Artificial Intelligence (AI). This issue aims to map the evolving landscape of innovative statistical research inspired and motivated by the rapid developments in AI, and to pioneer integrated statistical AI methods to advance scientific discovery and trustworthy AI (click here for more info)."
  },
  {
    "objectID": "posts/S3_interview.html",
    "href": "posts/S3_interview.html",
    "title": "Bridging Cells and Space: The Journey of scDesign3 Exploration",
    "section": "",
    "text": "Bridging Cells and Space: The Journey of scDesign3 Exploration\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n    \n    \n    \n        Dr. Jingyi Jessica Li\n        Dr. Jingyi Jessica Li, Professor of Statistics and Data Science (also affiliated with Biostatistics, Computational Medicine, and Human Genetics), leads a research group titled the Junction of Statistics and Biology at UCLA. With Ph.D. from UC Berkeley and B.S. from Tsinghua University, Dr. Li focuses on developing interpretable statistical methods for biomedical data. Her research delves into quantifying the central dogma, extracting hidden information from transcriptomics data, and ensuring statistical rigor in data analysis by employing synthetic negative controls. Recipient of multiple awards including the NSF CAREER Ward, Sloan Research Fellowship, ISCB Overton Prize, and COPSS Emerging Leaders Award, her contributions have gained recognition in the fields of computational biology and statistics.           \n        \n    \n\n    \n    The Article Link:scDesign3 generates realistic in silico data for multimodal single-cell and spatial omics\n    \n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        Our work aimed to provide a unified solution to the problems of method benchmarking and parameter inference in the single-cell and spatial omics field.\n        As breakthrough technologies, single-cell and spatial omics can unprecedentedly provide a multimodal view of the molecular biology phenomena (such as genome-wide gene expression and open chromatin regions) in individual cells. The excitement about these new technologies and the generated massive data has propelled a rapid development of computational methods, leading to thousands of computational methods being developed in less than a decade. As a result, the availability of numerous computational methods makes method benchmarking a pressing challenge. Fair benchmarking demands synthetic data that contain ground truths and mimic real data, thus calling for realistic simulators.\n        Motivated by the critical need for method benchmarking and other tasks (e.g., power analysis) requiring ground truths, my group has developed a series of mode-based single-cell simulators: scDesign (Li and Li, Bioinformatics 2019) and scDesign2 (Sun et al., Genome Biology 2021), with scDesign3 being the latest version. For each simulator, we propose a statistical model to be fitted to real data to describe a multi-variate distribution of cells; then we simulate synthetic cells by sampling from the fitted distribution. For example, for gene expression data, genes are the variables in the multi-variate distribution; for chromatin accessibility data, genomic regions are the variables. The advance of our simulators was based on the improvement of our proposed model. From scDesign to scDesign2, we added the consideration of variable correlations to make the model fit better to real data; as a result, the synthetic data become more realistic. From scDesign2 to the latest scDesign3, the most comprehensive simulator to our knowledge at the time of publication, we enlarged the model to account for comprehensive scenarios, including various cell latent states (discrete cell types or continuous cell trajectories), omics types, spatial locations, and experimental designs (Figure 1 Left).\n        An advantage of scDesign3 is that its probabilistic model unifies the generation and inference for single-cell and spatial omics data. The model’s interpretable parameters and likelihood enable scDesign3 to generate customized synthetic data and unsupervisedly assess the goodness-of-fit of cell latent states inferred by a computational method (Figure 1 Right). Hence, scDesign3 is not only a simulator that can generate realistic synthetic data but also a statistical model that can help interpret real experimental data. By inferring the parameters of the scDesign3 model, we can perform hypothesis testing tasks such as identifying the genes whose expression changes between cell types or along a cell trajectory, as well as comparing gene correlations between cell types.\n \n        \n        \n\n        How did the reviewers evaluate (praise) it?\n        The reviewers acknowledged the timeliness and significance of our work. Their quotes include\n        “Overall, this simulator is timely and invaluable for benchmarking computational methods and interpreting single-cell and spatial omics data.”\n        “The current manuscript scDesign3 proposed a substantial extension from the author’s previous work and addressed some of the key concerns with many current simulation studies; in particular, the capturing of the correlation structure between genes. This manuscript has two key components. The first is the focus on the creation of a generalizable simulation framework and the second component illustrates how the scDesign3 can be applied in three different modelling settings, (i) parameter estimation and inference, (ii) model selection, and (iii) perturbation).”\n        \n\n\n        If this achievement has potential applications, what are some specific applications it might have in a few years?\n        I think realistic synthetic data generation holds promise for critical applications in the single-cell and spatial omics field. First, I have been advocating the inclusion of synthetic negative control data to help users discern spurious discoveries made from a complex analysis pipeline. Such discoveries often arise from artifacts generated by the pipeline due to the “double-dipping” issue, which leads to the confirmatory bias. Second, synthetic data can potentially help alleviate the data imbalance issue, which can negatively affect tasks such as data integration and supervised learning. Third, synthetic data with added perturbations can be used for evaluating the stability of computational results. Given the increasing complexity of data analysis pipelines, involving many user-specified heuristic thresholds across multiple steps, it is essential to ensure the robustness of computational results.\n\n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        I will answer this question based on the way we generally conduct research. Before setting a research topic, we always think about three aspects: significance and novelty, validation approaches, and target user base. Given the competitive nature and widespread interest in single-cell and spatial omics, a comprehensive literature review is the cornerstone to justify the novelty and significance of the research topic. Equally important is the deliberation on how to validate the efficacy of our proposed method, whether through computational analysis or experimental verification. We must assess the availability of resources for validation and identify potential collaborators if such resources are lacking. Moreover, we must consider the prospective end-users of our method: will our method be useful for biologists who generate single-cell and spatial omics data, or will it only be interesting to method developers like ourselves? Importantly, how can we persuade biologists, who typically rely on visualization and empirical data, of the utility of our method? In general, I think answering these questions is essential to advocate a computational method to the biomedical scientists. \n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        An interesting story is about the term “real data,” used by statisticians in almost every methodology paper. As the scDesign projects were all about “synthetic data,” a term juxtaposed with “real data,” I initially used the term “real data” when introducing our scDesign work to biologists. Surprisingly, some biologists did not understand the concept of \"real data,\" asking questions such as \"What defines real data?\" and \"Is there such a thing as fake data?\" This confusion stemmed from the presumption that all data were generated from experiments and hence qualify as real. Aligned with this confusion, many biologists cannot appreciate the utility of simulation, considering simulation as purely a decoration of a computational method because simulation always works. I think realizing and recognizing these differences in mindsets (e.g., abstract thinking vs. empirical thinking) is an essential first step in fostering collaborations with biomedical scientists.\n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        We plan to develop an interactive software package for real-data-based synthetic data generation and applications. We will make the package compatible with the state-of-the-art single-cell analysis pipelines Seurat in R and Scanpy in Python. By providing users with the capability to generate customized synthetic data, we hope our software will enable users to benchmark computational methods on their specific datasets, leading to more rigorous and trustworthy discoveries.\n\n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        I view AI as a technology advance, similar to the advent of computers in the previous century. Statistics transitioned from its pre-computer era, where mathematical methods were the sole tools, to the computer era, where statistical analyses leveraged computing power to tackle previously impossible missions. Regardless of the tool—from mathematics to computers—the core of statistics, how to infer hidden truths from observed data, remains a timeless pursuit. Therefore, I am optimistic that the ongoing development of AI will pave the way for unprecedented advancements in statistical methodologies. I envision a synergy between the feature extraction capabilities of AI and the inferential toolkits of statistics, which can together propel data-driven scientific discovery. \n\n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n\n        I believe statisticians can play a pivotal role in elucidating the impact of proper versus improper use of statistics on scientific discoveries. Demonstrating the impact on concrete examples could significantly enhance the perceived value and influence of statistics within the scientific community.\n        \n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "posts/Vanguard of the Virus Fight.html",
    "href": "posts/Vanguard of the Virus Fight.html",
    "title": "Vanguard of the Virus Fight: Unveiling the lmpact of Updated Vaccines and Antivirals on Omicron Subvariants",
    "section": "",
    "text": "Vanguard of the Virus Fight: Unveiling the Impact of Updated Vaccines and Antivirals on Omicron Subvariants\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n\n    \n    The Article Link:sEffectiveness of XBB.1.5 vaccines and antiviral drugs against severe outcomes of omicron infection in the USA\n    \n\n    \n    \n    \n        Dr. Danyu Lin\n        Danyu Lin, Ph.D., is the Dennis Gillings Distinguished Professor of Biostatistics at the University of North Carolina at Chapel Hill. Dr. Lin has published 300 papers, with 44,000 citations and an h-index of 97 (https://scholar.google.com/citations?user=SG22hu0AAAAJ&hl=en). He was recognized as a Best Mathematics Scientist (National Ranking: 95; World Ranking: 172) by Research.com. The statistical methods he developed have been used in thousands of scientific studies. His publications on COVID-19 vaccines and treatments (5 in New England Journal of Medicine, 3 in JAMA journals, and 2 in Lancet journals —all as first and corresponding author) have been viewed 1 million times, cited by the CDC, FDA, EMA, and WHO, and reported by The New York Times, The Washington Post, and NBC News. Dr. Lin is an elected fellow of ASA and IMS, a recipient of Mortimer Spiegelman Award from American Public Health Association, and a recipient of George W. Snedecor Award from COPSS.\n        \n    \n\n    \n    \n    \n        Dr. Xiaofeng Wang\n        Xiaofeng Wang, Ph.D., is a Full Staff Member in the Department of Quantitative Health Sciences at Cleveland Clinic, and a Professor of Medicine at Cleveland Clinic Lerner College of Medicine of Case Western Reserve University. Dr. Wang has authored over 200 journal papers in the statistical and medical literature, as well as a number of book chapters and proceeding papers. He is an Elected Fellow of the American Statistical Association (ASA) and an Elected Member of the International Statistical Institute (ISI). His expertise lies in translational research, where he applies statistical methods to real-world problems, informing evidence-based practice, and driving meaningful impact in patient care and public health. His research interests include quantitative image analysis, real-world data analytics, and clinical machine learning models.\n        \n    \n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        The US Food and Drug Administration (FDA) authorized the use of the updated mRNA vaccines by Moderna and Pfizer-BioNTech on September 11, 2023 and the use of the updated adjuvanted vaccine by Novavax on October 3, 2023, “to provide better protection against serious consequences of COVID-19, including hospitalization and death”, without providing any clinical evidence. The updated vaccines contain a monovalent component of the Omicron XBB.1.5 subvariant. By the time these vaccines were deployed, XBB.1.5 subvariant was no longer prevalent. The effectiveness of the updated vaccines against currently circulating subvariants was unknown.\n        Meanwhile, the American College of Physicians has recommended ritonavir-boosted nirmatrelvir (Paxlovid) and molnupiravir, without ranking, for outpatient treatment of symptomatic COVID-19 patients at high risk of progressing to severe disease, whereas the National Institutes of Health Guidelines prefers nirmatrelvir. It would be helpful for physicians and patients to know which recommendation should be followed. In addition, it would be important to determine whether the decision to take antiviral drugs should depend on whether or not the patient had received an updated vaccine.\n        Against these backdrops, our paper provided much-needed clinical data from a large cohort study on the effectiveness of the three updated XBB.1.5 vaccines and the two oral antiviral drugs, as well as their interactions, against admission to hospital and death from currently circulating Omicron subvariants.1 We showed that both XBB.1.5 vaccines and antiviral drugs reduced the risk of serious consequences of infection with currently circulating Omicron subvariants. The effectiveness of updated XBB.1.5 vaccines was similar among patients aged ≥65 years and those aged &lt; 65 years, but the risks of hospitalization and death were much higher in the older age group. The effectiveness was higher in immunocompromised patients, who are at elevated risk of disease progression, than immunocompetent patients. In addition, the effects of molnupiravir and Paxlovid on disease progression were similar. Finally, the effectiveness of antiviral drugs was similar between recipients and non-recipients of the updated XBB.1.5 vaccines.\n \n        \n\n\n        How did the reviewers evaluate (praise) it?\n        The reviewers praised the timely and important nature of our work, as well as the clarity of our presentation:\n        “This is a timely report and answers important questions on the effectiveness of the XBB.1.5 boosters.” \n        “This concise, clearly written paper investigates the protective effect among PCR confirmed SARS-CoV-2 cases of XBB.1.5 vaccination, and separately of antiviral drug treatment with nirmatrelvir or molnupiravir, against progression of COVID-19 disease to hospitalization and death.”\n        “The paper is timely and addresses an important topic.”\n        The Editor-in-Chief wrote to us: “These are Important data, so I’m happy we get to publish them.”\n\n        \n\n\n        If this achievement has potential applications, what are some specific applications it might have in a few years?\n        Our work has important implications for the prevention and intervention strategies against COVID-19. Specifically, updated XBB.1.5 vaccines should be considered by all individuals, especially those who are aged 65 years or older or are immunocompromised, and either molnupiravir or Paxlovid can be prescribed to patients with COVID-19 who are at high risk of progressing to severe disease, regardless of their XBB.1.5 vaccination status.\n\n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        We recognized the importance of the research topic before the updated XBB.1.5 vaccines were authorized by the FDA. However, we had to wait for the updated vaccines to be deployed for several months to analyze the data, because we needed a large number of vaccine recipients and sufficient follow-up in order to obtain stable and precise estimates of the effects of updated vaccines on hospitalization and death. On the other hand, we wanted to publish our work as soon as possible, so as to maximize its impact.  Thus, there was a delicate balance in the timing of this research. \n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        This paper was published extremely fast, especially compared to a statistical publication. We submitted our paper on February 1, and the Editor-in-Chief sent the paper out to external reviewers on the same day. We received the initial decision on February 19 and were given 2 weeks to revise the manuscript. We submitted our revised manuscript in one week, and it was accepted in a few hours. We received the galley proof two days later. The paper was published a week later, on March 4.\n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        This study evaluated the effectiveness of updated vaccines and antiviral drugs against progression from infection to severe disease (hospitalization and death). We plan to evaluate the effectiveness of updated vaccines against infection, as well as the effectiveness of vaccination and (outpatient) antiviral treatment on long-COVID.\n\n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        Biostatistics offers indispensable support to the development of AI by providing rigorous analytical frameworks necessary to generate actionable insights from data, particularly in the context of electronic health records. Data quality is the key to the development of clinical AI models. Rigorous biostatistical methods should be employed to collect and process data.\n\n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n\n        Statisticians should be more involved in translational research, which allows statisticians to directly address practical challenges and solve real-world problems faced by practitioners. By developing and applying statistical methods to various scientific settings, statisticians can directly advance scientific knowledge.\n        \n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "posts/AI Day for Federal Statistics.html",
    "href": "posts/AI Day for Federal Statistics.html",
    "title": "AI Day for Federal Statistics: CNSTAT Public Event",
    "section": "",
    "text": "Join the essential dialogue on AI’s impact on federal statistics during the AI Day for Federal Statistics. This event, taking place on May 2, 2024, at the National Academy of Sciences Building in Washington DC, promises explorative discussions on AI applications, challenges, and practical tools for enhancing federal operations.\nFederal agencies will showcase their AI experiences through poster sessions, addressing methodological approaches, privacy concerns, and lessons learned.\nDon’t miss this opportunity to contribute to the future of federal statistical methods informed by AI.\nLearn more and register for the event.\nEvent Details: Date: May 2, 2024\nTime: 10:00AM - 5:30PM ET\nLocation: National Academy of Sciences Building, Washington DC\nContact: Madeleine Goedicke"
  },
  {
    "objectID": "posts/Advancing Health Research.html",
    "href": "posts/Advancing Health Research.html",
    "title": "Advancing Health Research through Ethical, Multimodal AI",
    "section": "",
    "text": "The NIH Office of Data Science Strategy (ODSS) launches the Advancing Health Research through Ethical, Multimodal AI Initiative, a call for applications to foster ethically aligned, data-driven AI research in biology, behavior, and health.\nKey Dates:\n\nRegister for the webinar: April 19, 2024, 2:00-3:00pm ET\n\nLetter of Intent Due: April 29, 2024, by 5:00pm local time\n\nFull Proposal Due: May 16, 2024, by 5:00pm local time\n\nDirect inquiries to: ODMultimodalAI@od.nih.gov\nThis initiative aims to develop new AI approaches for modeling and understanding complex systems to improve disease detection and treatment. Don’t miss out on contributing to this groundbreaking research effort.\nFor complete details, view the Research Opportunity Announcement."
  },
  {
    "objectID": "posts/Revolutionizing Cancer Risk Prediction.html",
    "href": "posts/Revolutionizing Cancer Risk Prediction.html",
    "title": "Revolutionizing Cancer Risk Prediction: The LFSPRO Validation Journey and its lmpact on Clinical Practice",
    "section": "",
    "text": "Revolutionizing Cancer Risk Prediction: The LFSPRO Validation Journey and Its Impact on Clinical Practice\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n\n    \n    The Article Link:sValidating Risk Prediction Models for Multiple Primaries and Competing Cancer Outcomes in Families With Li-Fraumeni Syndrome Using Clinically Ascertained Data\n    \n\n    \n    \n    \n        Dr. Wenyi Wang\n        Dr. Wang is a Professor of Bioinformatics and Computational Biology and Biostatistics at the University of Texas MD Anderson Cancer Center. She received her PhD from Johns Hopkins University and performed postdoctoral training in statistical genomics and genome technology at UC Berkeley with Terry Speed and at Stanford with Ron Davis. Wenyi’s research includes significant contributions to statistical bioinformatics in cancer, including MuSE for subclonal mutation calling, DeMixT for transcriptome deconvolution, Famdenovo for de novo mutation identification, and more recently, a pan-cancer characterization of genetic intra-tumor heterogeneity in subclonal selection and in tumor cell transcriptional plasticity respectively. Her group is focused on the development and application of computational methods to study the evolution of the human genome as well as the cancer genome, and further develop risk prediction models to accelerate the translation of biological findings to clinical practice.\n        \n    \n    \n    \n    \n        Dr. Hoai Nam Nguyen\n        Hoai Nam Nguyen defended his PhD thesis in Statistics on “Characterization of cancer development and recurrence through mathematical and statistical modeling” under the supervision of Dr. Wenyi Wang, Dr Marek Kimmel, at Rice University on March,22,2024. \n        \n    \n\n\n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        Our work, which was recently published in the Journal of Clinical Oncology (JCO), contributes to the resolution of an existing problem within the field: there is a plethora of risk predictions models that have been developed for hereditary cancer syndrome, but the fact remains that very few of them are being utilized in real clinical settings. We believe that a major obstacle is to convince healthcare providers (e.g., clinicians, genetic counselors) to use these data-driven approaches. Our software suite, LFSPRO, consists of two risk prediction models to characterize cancer risks in families with Li-Fraumeni syndrome (LFS). In order to overcome the mentioned hurdle, we conducted a validation study of LFSPRO on a patient cohort that was collected as part of the Clinical Cancer Genetics (CCG) program at MD Anderson Cancer Center (MDACC). Unlike most other cohorts, which are meticulously collected for research purposes, our unique patient cohort closely resembles what genetic counselors observe in their counseling sessions, where data collection only takes up 30 minutes of time. Our validation results were indeed lower compared to the previous validation studies on research cohorts, but still at a reasonable level. Due to the nature of our validation dataset, these results provided strong indication that LFSPRO had the potential to assist decision making in clinics. In a bigger picture, our paper shows that model performance can deteriorate on less well-behaved datasets, hence highlighting the importance of clinical validation studies in bridging the gap between methodology research labs and clinics. (Also see MDA news)\n\n\n        How did the reviewers evaluate (praise) it?\n        Our manuscript was evaluated by both clinical and statistical reviewers. It was also read by the editors during the peer review process. In general, they recognized the significance and uniqueness of our study, as well as the efforts that we made to help families with hereditary cancer syndromes via a statistically sound approach. \n        Associate editor Robert G. Maki MD/PhD/FACP/FASCO from MSKCC wrote the relevance of our work: A novel model helps better predict risk of cancer development in patients with Li-Fraumeni syndrome. These types of models, along with primary cancer screening, will hopefully improve the care for patients with familial cancer syndromes.\n        Quotes from the anonymous reviewers:\n        “The validation of a risk prediction model for LFS that can be used clinically would change clinical practice for the better, I applaud the authors for their work in this field.”\n        “The strengths of this work include its potential to provide useful modeling despite the ongoing problem of missing information in a single clinical genetic counseling session.”\n\n        \n\n\n        If this achievement has potential applications, what are some specific applications it might have in a few years?\n        Our goal is to disseminate the risk prediction models we developed to clinics to assist decision making. Currently, we are experimenting them with a small group of genetic counselors at MDACC, and performing a concordance study to evaluate how LFSPRO performs relative to the more established clinical criteria (e.g., Chompret criteria) in predicting deleterious germline TP53 mutations, prospectively. More specifically, our publication is based on a retrospectively collected patient cohorts from the clinic. We are currently writing up new findings from a prospectively collected patient cohort seen by genetic counselors over the past two years at MD Anderson. As these results remain positive, our clinical collaborator has engaged a patient population to contemplate on a randomized clinical trial on LFSPRO, which should represent the last step before its full integration into clinics. We have actually received requests from several clinics in the US to use LFSPRO right away.\n\n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        Given the raw dataset, we preprocessed it to obtain a reformatted dataset that was ready for LFSPRO. This stage involved frequent communication between us and our clinical collaborators to understand the data in more details and to clarify ambiguity. \n        \n        In a typical counseling session, which is about an hour in length, the genetic counselor spends the first 20-30 minutes to collect family history of the counselee before performing a comprehensive risk assessment. As such, the collected information only represents a snapshot of the family history, with a lot of family members having missing ages at last contact or missing ages at cancer diagnoses. Unlike research-based datasets, there are usually no time and resources to obtain more complete information. Thus, an important part of our validation study was to agree on a way to handle this issue of missing information.\n        \n        Since the goal of our study was to expedite the clinical utility of LFSPRO, we also wanted our validation study design to closely resemble real clinical settings. For example, since the National Comprehensive Cancer Network (NCCN) guidelines recommend testing for all close relatives of a positively tested individual, we strongly emphasized the models’ utility to accurately predict TP53 mutations when no genotype information is available within the family. When selecting statistical measures of model performance, we decided to comprehensively evaluate the models in both discrimination and calibration, since both of them are important in clinical decision making.\n        \n        Finally, we spent a lot of time writing up the manuscript. Even though all the analyses had been done, it was challenging to highlight the results in the best possible way. We, for example, constructed a figure to visually describe how the data collection process is different for research protocol-based and clinical counseling-based cohorts. This figure received positive comments from one of the clinical reviewers during the peer-review process. We then further computed key summary statistics to emphasize the differences between the two types of patient cohorts. We believe that these changes helped deliver the key points to the reviewers at JCO, who are not familiar with the statistical modeling or the technical language. Again, the clinical expertise of our collaborators was really helpful during this final stage.\n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        Nam: Due to the clinical nature of our study, we closely worked with our clinical collaborators at MDACC at all stages during the research process. I started working on this project when I was still a junior PhD student in Statistics at Rice University. Coming from a technical background with a bachelor degree in Math and little collaboration experience, I soon realized that statisticians and clinicians had very different communication styles. In particular, I had difficulty communicating effectively with our collaborators and conveying my research ideas and results in the manuscript in a way that was approachable to the reviewers. Nevertheless, I recognized that I would need to adapt to this new setting in order to expedite the productivity of our research group as a whole. We went back and forth a lot, especially during the manuscript stage, to find a way that best emphasized the clinical utility of our risk prediction models. With the help of my PhD advisor Wenyi Wang, I am grateful that I managed to overcome this hurdle and push the project to the finish line. \n        \n        Wenyi: When I received this dataset from a newly formed collaboration with Dr. Banu Arun, co-director of the Clinical Cancer Genetics program at MD Anderson, I was still feeling sad about losing my 10-year long collaborator Dr. Louise Strong (to retirement), who is considered “the mother of LFS” and spent 40 years collecting/updating meticulous data from families with LFS. We published many modeling and cancer research papers together. But she had to retire. I also did not like the significant amount of missing data in this new dataset, as a statistician data snob. But somehow, in the process of this study, through meeting with Banu’s GC team every week, a lightbulb went off. I realized that this dataset is much more closer to reality and we will have to show LFSPRO works in this data setting to change many clinicians and GCs’ mindset: mathematical models may work with perfect data, but clinical criteria consisting of simple sentences are still better for the clinical decision-making. This mindset has prevented the field of risk prediction modeling from moving forward.\n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        We are conducting a prospective concordance study on LFSPRO to further evaluate its clinical utility in predicting deleterious germline TP53 mutations. We hope to achieve better results than the Chompret criteria, which are recommended in the National Comprehensive Cancer Network (NCCN) guidelines. If the results support our models, it will be another major step towards our end goal.\n        We are also developing a joint statistical framework that estimates cancer-specific age-at-onset penetrances beyond the first primary cancer, thus having the potential to assist risk assessment for cancer survivors. This model can achieve prediction objectives that the current models in LFSPRO cannot. Our manuscript has recently been submitted to a statistical journal. We plan to integrate this new model to LFSPRO to have a complete software suite for risk predictions in families with Li-Fraumeni syndrome. In order to validate the clinical utility of the joint model, we will perform an extensive validation study on multiple patient cohorts from different cancer institutes across the United States and from Germany. This ensures that the model is robust to variations between datasets (e.g., data quality, ascertainment criteria). \n\n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        AI offers a wide range of machine learning methods to automate the analysis of complex datasets in healthcare and biomedical science (e.g., medical imaging data were manually examined by radiologists). However, there are still a lot of data types that are more relevant to traditional statistical methods (e.g., time-to-event patient data), and we see no reasons that their significance will diminish in a foreseeable future. Analyses of these different data types are not necessarily separate, since there have been hybrid models that attempt to combine them to achieve better prediction results. This represents a collaboration opportunity between biostatisticians and AI developers. In addition, bridging the gap between AI research labs and clinics is highly challenging since most of these AI models are black boxes (i.e., we do not understand how the output is computed). Extensive validation studies are, therefore, even more relevant to ensure that the models can perform well in all real-world settings. Biostatisticians, with their expertise in clinical trials and study design, can help expedite this process.  \n\n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n\n        We would like to thank the patients for contributing their data to our studies. The LFS community is a very special one that is dear to my heart. Every two years, the LFS association (https://www.lfsassociation.org/) holds a 2-day conference that brings clinicians, biologists (computational and experimental) and patients together. My team has been attending this conference over the past 10 years. Talking with these patients and their family members has been an extremely humbling and motivating experience. Although my laboratory research primarily focuses on tumor heterogeneity and evolution, I always find joy in spending time on this completely separately line of research. \n        \n\n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "posts/fireside conversation.html",
    "href": "https://statsupai.com/pages/fireside/firesidenews.html",
    "title": "Statistics and AI - A Fireside Conversation",
    "section": "",
    "text": "Statistics and AI - A Fireside Conversation\n                 Co-hosts: Stats Up AI Alliance and International Chinese Statistical Association (ICSA)\n              \n            \n          \n        \n      \n      \n\n    \n\n    \n\n      \n        \n\n          \n          \n            \n              \n            \n          \n          \n\n          \n\n            \n\n              \n                                \n                \n                   11:00 am-1:00 pm ET, March 17, Sunday\n                  Why Are We Here? \n                  Recent fast developments in AI have led to excitement across the entire research community. Statistics is no exception. Many statisticians are feeling both excited and apprehensive about what this new era of AI implies for the future of Statistics and how statistics can contribute to empowering trustworthy AI. Informal discussions have taken place everywhere, online and offline. To leverage this energy and identify actionable initiatives for our discipline, Stats Up AI and ICSA organized a fireside chat on March 17 on \"empowering statistics in the era of AI\" with three panels of thought leaders, hoping to drive more community-level efforts to empower statistics and statisticians and make an impact in these exciting times of AI. \n                  \n                  \n                  Tian Zheng initiated the proceedings with an expression of gratitude towards the association and the esteemed panelists, underscoring the importance of their insights and indicative of the topic's significance. Following Tian Zheng's opening remarks, Xihong Lin delved deeper into the essence of the fireside chat, emphasizing the critical role of statistics in comprehending and influencing both scientific research and societal decision-making in the age of artificial intelligence. Lin outlined the event’s structured approach, encompassing three focused sessions on the challenges and opportunities in statistical theory, methods, and application research in the AI era.\n                  \n\n                \n                \n\n              \n\n            \n\n            \n\n            \n\n              \n                \n\n                \n                \n                   \n                  Fireside Agendas\n                   Introduction: Tian Zheng (Columbia University);  Opening: Xihong Lin (Harvard University)\n                \n                \n\n              \n\n              \n\n                \n                \n                  \n                  Session 1:\n                  Statistical Theory & Methods, Applications and AI\n                  \n                  \n                    Moderator: Xihong Lin (Harvard U)\n                    Hongtu Zhu (University of North Carolina at Chapel Hill)\n                    Jiashun Jin (Carnegie Mellon University)\n                    Tianxi Cai (Harvard University)\n                    Haoda Fu (Eli Lilly)\n                    Tracy Ke (Harvard University)\n                    Harrison Zhou (Yale University)\n                    Discussant: Dave Donoho (Stanford University)\n                  \n                \n                \n\n              \n              \n\n                \n                \n                  \n                  Session 2:\n                  Statistics, ML, and Data Science Journals\n                  \n                    Moderator: Heping Zhang (Yale University)\n                    Ji Zhu (University of Michigan)\n                    Chengchun Shi (London School of Economics and Political Science)\n                    Xiao-Li Meng (Harvard University)\n                    Discussant: Dave Donoho (Stanford University)\n                  \n                \n                \n\n              \n              \n\n                \n                \n                  \n                  Session 3:\n                  Statistical education in the age of AI \n                  \n                      Moderator: Peter Song (University of Michigan)\n                      Wenyi Wang (MD Anderson Cancer Center)\n                      Hulin Wu (University of Texas at Houston)\n                      Qiang Sun (University of Toronto)\n                      Bin Yu (University of California at Berkeley)\n                      Discussant: Dave Donoho (Stanford University)\n                  \n\n                \n                \n\n              \n\n            \n            \n              \n                \n\n\n                \n                \n\n                \n                \n                  Session 1\n                  The challenges and opportunities for the statistics coumminity in the era of AI\n                  The first session of the conversation is on the challenges and opportunities for statistical theory and methods in the era of AI. Hongtu Zhu from UNC-Chapel Hill’s discourse further illuminated the pressing challenges and burgeoning opportunities at the intersection of statistics and AI, emphasizing the transformative impact of academic innovations like ImageNet and convolutional neural networks. Jiashun Jin from Carnegie Mellon University shared insightful observations and suggestions regarding AI and theoretical statistics based on his academic experience and collaboration with Google researchers. Tianxi Cai from Harvard University discussed the vast opportunities and pressing action items in the field of statistics, particularly in the context of AI's growing influence and the increasing amount of complex data. By reviewing the development of certain fundamental deep learning algorithms, Haoda Fu from Eli Lilly emphasized the need for Architecture-Algorithm Co-Design thinking, identifying four areas for development: low-level programming, data structures and algorithms, optimization, and design patterns. Tracy Ke from Harvard explored the intersection and distinct roles of statistics and AI, sharing an enlightening experiment on topic modeling using Large Language Models. Ke highlighted the clear role of theory in statistics to inspire new methods and identify method limitations in AI. Harrison Zhou from Yale explored the relationship between statistical theory, AI foundations, and their applications in data science. He also suggested incorporating AI researchers into editorial boards of journals and encouraging junior faculty to publish in top AI conferences, emphasizing the need for statisticians to be part of the AI evaluation process. David Donoho, in his discussion, provided a reflective view on the evolving landscape of statistical decision theory, AI, and their applications in data science. He discussed the perceived threat of AI overshadowing statistics, suggesting that statisticians should adopt a more welcoming approach towards AI, perhaps even \"wearing AI T-shirts,\" to foster participation and collaboration.\n                  See the video\n\n                  \n                      \n                  \n\n                \n                \n\n\n\n                            \n                \n                  Session 2\n                  Publication process of statistics in the era of AI\n                  The second session of the conversation focused on how to improve the publication process in the era of data science and AI. Annie Qu as the current editor of the Journal of American Statistics Association (JASA) highlighted the problem of slow journal publication, particularly problematic in the rapidly advancing field of AI. She advocated for early rejection of papers with little potential and proposed rewarding diligent associate editors and referees to encourage better and faster reviews. Announcing a special issue in JASA on science and AI, Annie expressed hope for fostering the integration of statistics and AI to advance scientific discovery. Following Annie Qu's discussion on the publication process, Ji Zhu as the editor of Annals of Applied Statistics (AoAS) emphasized the importance of innovation not just from the authors' standpoint but also from the perspective of the journal editors, associate editors, and reviewers. He floated the idea of open reviews post-acceptance to foster discussion and increase visibility. He advocated for dual publications to make significant impacts, suggesting that discoveries be published in domain-specific journals while sophisticated statistical modeling is featured in statistical journals. Chengchun Shi compared the publication processes between statistical journals and machine learning conferences. He proposed several changes to improve the efficiency of the statistical publication process, including short review cycles, reducing the number of rounds, increasing number of references, and broadening the scope of journals. Xiao-Li Meng from Harvard shared his thoughts on the three Ps for statistical journals. He suggested statistical journals to be more Proactive in directing statistical research within the data science ecosystem; he stressed Promoting communication with the broader data science community; he also highlighted the need for journals to focus more on the data science Process rather than just the end products. Following these discussions, David Donoho provided a reflective critique on the evolution of statistical publication and research in light of the rapid changes brought by advancements in computer science and artificial intelligence.\n                  See the video\n                  \n                      \n                  \n\n                \n                \n\n                            \n                \n                  Session 3\n                  Advancing statistical next generation pipelines and resources in the age of AI\n                  The third session centers on statistical education in the age of AI. Wenyi Wang from MD Anderson compared statistics and computational biology in attracting students and fundings. She emphasized the crucial role of statistics in the age of AI and called for better leadership training in statistics and efforts to attract more talents to the field. Hulin Wu addressed the pressing question: Should statistics training expand to encompass data science and artificial intelligence (AI)? He discussed the current transition from statistics to data science and highlighted the challenge of balancing expansion into new fields while preserving statistics' distinct identity and principles. Qiang Sun discussed the evolution of statistical training in the era of data science and AI. He pointed out the discipline's shift towards production, emphasizing that statistical work must translate into products for the greater benefit of science. Dr. Sun proposed a bold reimagining of the curriculum to include deep learning, AI, and essential engineering skills and advocated for a more flexible and inclusive mindset in faculty and student recruitment. Bin Yu discussed the evolving nature of statistics in relation to data science and AI, emphasizing the interdisciplinary nature of these fields. She suggested to integrate machine learning as part of statistics curriculum to tackle the emerging challenges in AI, particularly focusing on trustworthiness, safety, and alignment with human intent. Highlighting the changes in academic courses over the past decade, Dr. Donoho pointed out shifts from traditional subjects to more current topics like machine learning. This signifies a transformative period for educational curriculums across mathematics and computer science departments. In conclusion, Dr. Donoho and fellow panelists advocated for proactive efforts to remodel statistics education to meet the demands of a rapidly changing world while maintaining the discipline's fundamental principles.\n                  See the video\n                  \n                      \n                  \n\n                  \n                \n\n\n                \n\n            \n\n            \n\n          \n\n        \n      \n\n    \n\n    \n\n    \n    \n      \n        \n          \n          \n          \n            \n            Table Reservation\n          \n          \n          \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n                  Not specified\n                  1 Preson\n                  2 People\n                  3 People\n                  4 People\n                  5 People\n                  6 or more\n                \n              \n              \n                \n                  \n                \n              \n              \n                \n                  Not specified\n                  10:00 am\n                  11:00 am\n                  12:00 pm\n                  1:00 pm\n                  2:00 pm\n                  3:00 pm\n                  4:00 pm\n                  5:00 pm\n                  6:00 pm\n                  7:00 pm\n                  8:00 pm\n                  9:00 pm\n                  10:00 pm\n                \n              \n              \n                \n              \n            \n            Reserve a table"
  },
  {
    "objectID": "posts/S5_interview.html",
    "href": "posts/S5_interview.html",
    "title": "iStar in Focus: Enhancing Spatial Transcriptomics with High-Resolution Histology for Precise Molecular Mapping",
    "section": "",
    "text": "iStar in Focus: Enhancing Spatial Transcriptomics with High-Resolution Histology for Precise Molecular Mapping\n\n    \n    \n    \n    \n    \n    \n    \n\n\n\n    \n\n    \n    The Article Link:Inferring super-resolution tissue architecture by integrating spatial transcriptomics with histology\n    \n\n    \n    \n    \n        Dr. Mingyao Li\n        Dr. Mingyao Li is a Professor of Biostatistics and Digital Pathology at the University of Pennsylvania Perelman School of Medicine. She received her PhD in Biostatistics from the University of Michigan in 2005. She was trained as a statistical geneticist, but since joining the faculty at UPenn in 2006, she has gradually transitioned her research from traditional statistical genetics to statistical genomics, and more recently to molecular imaging and digital pathology. The primary goal of her research is to develop computational tools to tackle genetics and genomics related problems using modern machine learning and AI techniques. She is particularly interested in translational research that has a direct impact on human health.\n        \n    \n    \n    \n    \n        Dr. David Zhang\n        Dr. Daiwei (David) Zhang received his PhD in Biostatistics and Scientific Computing from the University of Michigan in 2021. His doctoral research centered on developing statistical and machine learning methods for analyzing genetics and imaging data. Since joining Mingyao Li’s lab as a postdoc researcher in October 2021, David has focused on creating AI tools for the integrative analysis of spatial omics and pathology imaging data. In August 2024, he will join the Departments of Biostatistics and Genetics at UNC Chapel Hill as a tenure track assistant professor, where his lab will focus on developing AI tools to address challenges in digital medicine. \n        \n    \n\n\n\n\n    \n    \n        Regarding the research background and significance, does this work discover new knowledge or solve existing problems within the field? Please elaborate in detail.\n        Selected as Nature Methods’ 2020 Method of the Year, Spatial Transcriptomics (ST) has revolutionized our understanding of how tissues are spatially organized and how cells communicate with each other. Despite the availability of many ST platforms, none of them offer a comprehensive solution. An ideal ST platform for biological discovery should provide single-cell resolution, encompass the entire transcriptome, cover a large tissue area, and be cost-effective. However, producing such ST data with existing platforms is difficult. To address this challenge, we developed iStar (Inferring Super-Resolution Tissue Architecture), https://www.nature.com/articles/s41587-023-02019-9, an AI tool designed to produce such ideal ST data by leveraging high-resolution information provided by histology images. iStar utilizes an image feature extraction process that mimics a pathologist’s examination of histology images, enabling the virtual prediction of gene expression with near single-cell resolution. The results from iStar offer both detailed views of individual cells and a broader perspective on the full spectrum of gene activity. This tool exemplifies how AI-enabled digital pathology can enhance the analysis of spatial transcriptomics data.\n\n        How did the reviewers evaluate (praise) it?\n        This paper underwent the smoothest peer-review process that I have ever experienced. Even in the initial round of review, one reviewer commented, “The method demonstrated a significant and meaningful advancement for the field. I will recommend accepting with revision as a brief communication in Nature Biotechnology.” Following our first revision, which clarified some of the technical details, the paper was accepted in principle.\n\n        \n\n\n        If this achievement has potential applications, what are some specific applications it might have in a few years?\n        The pathology imaging technique provides both highly detailed views of individual cells and a broader look of the full spectrum of how people’s genes operate, which would allow doctors and researchers to see cancer cells that might otherwise have been virtually invisible. As such, iStar can be used to determine whether safe margins are achieved through cancer surgeries and automatically provide annotation for microscopic images, paving the way for molecular disease diagnosis at that level. In addition, iStar can be utilized to automatically detect critical anti-tumor immune formations called “tertiary lymphoid structures,” whose presence correlates with a patient’s likely survival and favorable response to immunotherapy, which is often given for cancer and requires high precision in patient selection. This means that iStar could be a powerful tool for determining which patients would benefit most from immunotherapy.\n\n        Can you recount the specific steps or stages from setting the research topic to the successful completion of the research?\n        This project started in October 2021, when David joined my lab as a postdoc. Initially, our goal was to predict spot-level gene expression in histology images for samples lacking gene expression data. Despite facing many challenges and early setbacks, David’s persistence led to innovative approaches for extracting information from the histology images. After many attempts, we landed on a hierarchical vision transformer approach for image processing, that computationally mimics how a pathologist examines a histology image in clinic.  As I will detail in my answer to the next question, we discovered that this approach effectively extracts features from histology images, and promted us to shift our focus. Rather than focusing on out-of-subject gene expresson prediction, we focused on enhancing the spatial resolution of gene expression in the 10x Visium platform, the most popular platform for ST. By October 2022, we had developed a prototype of the algorithm. The subsequent phase of the project involved identifying biologically and clinically relevant questions that could be explored using our predicted super-resolution gene expression. We engaged with many collaborators, including pathologists, cancer biologists, nepherologits, and neurologists, to review the results and provide biological interpretations. These collaborative efforts significantly enhanced the project’s impact. Without those interesting case studies, this paper wouldn’t have appeared in Nature Biotechnology.\n        \n\n        Were there any memorable events during the research? You can tell a story about anything related to people, events, or objects.\n        A particularly memorable event occurred during a meeting in July 2022 when David presented a tissue segmentation result that utilized hierarchically extracted histology image features. Upon seeing that result, I immediately realized the potential of these features to predict gene expression. Since the features were extracted at the super-pixel level, approximately equivalent to the size of a single cell, it became apprarent that we could use these features to learn the relationship between histology and gene expression. This relationship would allow us to predict near single-cell level gene expression not only within directly measured spots but also in tissue gaps lacking spot coverage. \n        \n        \n\n        Is there a follow-up plan based on this research? If so, please elaborate.\n        iStar’s capabilities can be expanded in many different ways. Currently, we are exploring the use of ST data with single-cell resolution to train models that predict gene expression. We are also investigaging the potential for predicting gene expression in large-sized tissues that exceed the capture area of standard ST platforms. Another exciting direction is the reconstruction of 3D tissue volumes for gene expression analysis. Our ultimate goal is to enable virtual ST on tissue samples from biobanks. If successful, this would facilitate the development of diagnostic and prognostic models for diseases, generate spatial molecular tissue references, and enhance disease diagnostis, treatment recommendation, and personalized medicine.\n\n        Without a doubt, AI is one of the hot topics of 2023, requiring extensive data support in its development. What assistance can biostatistics offer to the development of AI?\n        Both David and I received our PhDs in Biostatistics from the University of Michigan. During our PhD studies, we worked on imaging and genetics problems, which trained our computing skills—critical for our transition into AI research. Biostatisticians, especially those with strong computing abilities and experience in handling large datasets, can perform as well as those trained in computer science. The statistical training we received, coupled with our domain knowledge, is invalable for identifying the most pertinent biomedical problems to address using AI approaches.\n\n        Besides the above questions, is there anything else about this achievement that you would like to add? If so, please add it below.\n\n        Domain knowledge is crucial in biomedical research. The impact of a paper largely depends on the significance of the question it addresses. Although the techniques employed are important, their importane is secondary to that of the scientific question. Often, the emphasis is mistakenly placed on the technical aspects of research, which may limit its relevance primarily to statisticians. To engage a broader audience, it is essential to communicate in the language of domain experts and to identify the most pressing questions. Acquiring domain knowledge requires years of experience. We are fortunate to work at the Penn School of Medicine, a hub for collaborative and translational research that shapes our research approach and deepens our domain knowledge.\n        \n\n        \n\n    \n    \n        Edited by: Shan Gao\n        Proofread by: Hongtu Zhu\n    \n\n\nPage Views:"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nNSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nStatistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program\n\n\n\n\n\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nNSF Grant Opportunity: Mathematical Foundations of Artificial Intelligence\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nNIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nNSF-led National AI Research Resource Pilot awards first round access to 35 projects in partnership with DOE\n\n\n\n\n\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\niStar in Focus: Enhancing Spatial Transcriptomics with High-Resolution Histology for Precise Molecular Mapping\n\n\n\n\n\n\n\nInterviews\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nStatistics and AI - A Fireside Conversation\n\n\n\n\n\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nRevolutionizing Cancer Risk Prediction: The LFSPRO Validation Journey and its lmpact on Clinical Practice\n\n\n\n\n\n\n\nInterviews\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nAdvancing Health Research through Ethical, Multimodal AI\n\n\n\n\n\n\n\nOpportunities\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nAI Day for Federal Statistics: CNSTAT Public Event\n\n\n\n\n\n\n\nOpportunities\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nBangyao Zhao\n\n\n\n\n\n\n  \n\n\n\n\nVanguard of the Virus Fight: Unveiling the lmpact of Updated Vaccines and Antivirals on Omicron Subvariants\n\n\n\n\n\n\n\nInterviews\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nBridging Cells and Space: The Journey of scDesign3 Exploration\n\n\n\n\n\n\n\nInterviews\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nUnveiling Immunity Across Cancers: An Interview with Dr. Pei Wang\n\n\n\n\n\n\n\nEvents\n\n\nInterviews\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nConducting research with UK biobank\n\n\n\n\n\n\n\nVideos\n\n\nResources\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nHenry Ye\n\n\n\n\n\n\n  \n\n\n\n\nCall proposal for JASA special issue on AI\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nHenry Ye\n\n\n\n\n\n\n  \n\n\n\n\nConducting research with All of Us\n\n\n\n\n\n\n\nVideos\n\n\nResources\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2024\n\n\nHenry Ye\n\n\n\n\n\n\n  \n\n\n\n\nTownhall meeting on the role of statisticians for the future of AI\n\n\n\n\n\n\n\nEvents\n\n\nVideos\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nStatistics for the Future of AI\n\n\n\n\n\n\n\nEvents\n\n\nVideos\n\n\nResources\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nStatistical Aspects of Trustworthy Machine Learning\n\n\n\n\n\n\n\nResources\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nJournal of Data Science calls for contributions to a special issue on the same topic\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nShan Gao\n\n\n\n\n\n\n  \n\n\n\n\nData and AI Intensive Research with Rigor and Reproducibility (DAIR³)\n\n\n\n\n\n\n\nOpportunities\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nShan Gao\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/NSF-led National AI Research Resource.html",
    "href": "posts/NSF-led National AI Research Resource.html",
    "title": "NSF-led National AI Research Resource Pilot awards first round access to 35 projects in partnership with DOE",
    "section": "",
    "text": "The U.S. National Science Foundation (NSF) in partnership with the Department of Energy (DOE) has announced the first awards to 35 projects through the National Artificial Intelligence Research Resource (NAIRR) Pilot. These awards grant computing time on advanced systems to support AI research initiatives, including deepfake detection, AI safety, medical diagnoses, and more. This marks a significant step in responsible AI research and broadening access to AI tools nationwide. Further details and applications for future resources are available on the NAIRR Pilot portal.\nTo learn more about the NSF-led National AI Research Resource Pilot, visit the official announcement."
  },
  {
    "objectID": "posts/National Science Foundation Grant Opportunity.html",
    "href": "posts/National Science Foundation Grant Opportunity.html",
    "title": "NSF Grant Opportunity: Mathematical Foundations of Artificial Intelligence",
    "section": "",
    "text": "The Grants.gov notice summarizes a funding opportunity with the number 24-569, titled “Mathematical Foundations of Artificial Intelligence,” offered by the National Science Foundation (NSF). It is a discretionary grant within the science, technology, and research and development funding category, with an absence of cost sharing or matching requirements.\nKey points about the funding opportunity include:\n\nFunding Instrument Type: Grant\nApplicable CFDA Numbers: 47.041, 47.049, 47.070, 47.075\nPosting Date: May 02, 2024\nApplication Closing Date: October 10, 2024\nArchive Date: November 08, 2026\nEstimated Total Program Funding: $8,500,000\nAward Ceiling: $1,500,000\nAward Floor: $500,000\n\nEligibility for application is limited to non-profit, non-academic organizations, and institutions of higher education (IHEs) in the United States. Principal Investigators (PIs) must hold a tenured or tenure-track position or a full-time research or teaching position at a U.S.-based institution eligible to submit proposals. There are also exceptions for family or medical leave.\nThe grant program aims to support research that explores the mathematical and theoretical foundations of Artificial Intelligence. The goal is to gain a clearer understanding of AI capabilities, limitations, and future potential. Research should address fundamental questions and seek to develop new, mathematically-grounded principles for the design and analysis of AI systems. Interdisciplinary collaboration across various fields such as mathematics, statistics, computer sciences, engineering, and social and behavioral sciences is encouraged to enable progress in AI that is sustainable, socially responsible, and trustworthy.\nFor additional information and details on how to apply, interested parties are directed to refer to NSF Publication 24-569 and contact tsgovsupport@nsf.gov for support."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html",
    "href": "posts/NIH Funding Opportunity.html",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "",
    "text": "Participating Organizations: National Institutes of Health (NIH), National Human Genome Research Institute (NHGRI), National Institute on Aging (NIA), Office of Data Science Strategy (ODSS)\nFunding Opportunity Title: Machine Learning/Artificial Intelligence (ML/AI) Tools to Advance Genomic Translational Research - Development Sites (MAGen) (UG3/UH3 Phase without Clinical Trials)\nAnnouncement Type: New\nFunding Opportunity Number (FON): RFA-HG-24-004\nCompanion Funding Opportunity: RFA-HG-24-005, UG3/UH3 Coordinating Center (CC)\nCFDA Numbers: 93.172, 93.310, 93.866\n\n\n\nThe funding aims to develop ML/AI tools to enhance predictions for individuals with pathogenic genetic variants, focusing on integrating ethical, legal, and social implications (ELSI) within these developments. The establishment of the MAGen Research Consortium is a major goal.\n\n\n\n\nPosted Date: May 10, 2024\nOpen Date: June 26, 2024\nLetter of Intent Due Date: June 26, 2024\nApplication Due Date: July 26, 2024, by 5:00 PM local time\nExpiration Date: July 29, 2024"
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#key-dates",
    "href": "posts/NIH Funding Opportunity.html#key-dates",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "",
    "text": "Posted: May 10, 2024\nOpen Date: June 26, 2024\nLetter of Intent Due: June 26, 2024\nApplication Due: July 26, 2024, by 5:00 PM local time\nExpiration Date: July 29, 2024"
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#magen-project-goals-activities",
    "href": "posts/NIH Funding Opportunity.html#magen-project-goals-activities",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "MAGen Project Goals & Activities:",
    "text": "MAGen Project Goals & Activities:\nDevelop ML/AI tools and an ELSI framework for genomic translational research. Identify at least 4 candidate genes with pathogenic variants for tool development and cross-validation. Develop tools for at least one gene and cross-validate tools for 2-4 others. Conduct ELSI research to explore issues related to ML/AI tool integration in genomic medicine."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#participation-and-roles",
    "href": "posts/NIH Funding Opportunity.html#participation-and-roles",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Participation and Roles",
    "text": "Participation and Roles\nPD/PIs are to lead the project responsibly, while NIH will have a significant role in steering the committee and other activities."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#part-1-overview-information",
    "href": "posts/NIH Funding Opportunity.html#part-1-overview-information",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "",
    "text": "Participating Organizations: National Institutes of Health (NIH), National Human Genome Research Institute (NHGRI), National Institute on Aging (NIA), Office of Data Science Strategy (ODSS)\nFunding Opportunity Title: Machine Learning/Artificial Intelligence (ML/AI) Tools to Advance Genomic Translational Research - Development Sites (MAGen) (UG3/UH3 Phase without Clinical Trials)\nAnnouncement Type: New\nFunding Opportunity Number (FON): RFA-HG-24-004\nCompanion Funding Opportunity: RFA-HG-24-005, UG3/UH3 Coordinating Center (CC)\nCFDA Numbers: 93.172, 93.310, 93.866\n\n\n\nThe funding aims to develop ML/AI tools to enhance predictions for individuals with pathogenic genetic variants, focusing on integrating ethical, legal, and social implications (ELSI) within these developments. The establishment of the MAGen Research Consortium is a major goal.\n\n\n\n\nPosted Date: May 10, 2024\nOpen Date: June 26, 2024\nLetter of Intent Due Date: June 26, 2024\nApplication Due Date: July 26, 2024, by 5:00 PM local time\nExpiration Date: July 29, 2024"
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#part-2-full-text-of-announcement",
    "href": "posts/NIH Funding Opportunity.html#part-2-full-text-of-announcement",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Part 2: Full Text of Announcement",
    "text": "Part 2: Full Text of Announcement\n\nSection I: Background and Objectives\nDescribing the background, the need for tools to enhance genomic and non-genomic data analysis in predicting diseases.\n\n\nSection II: Award Information\n$4.8 million is committed to fund 2-4 awards, each with a limit of $1.6 million per year for a duration of five years.\n\n\nSection III: Eligibility Information\nIncludes a range of US institutions, both academic and profit-oriented."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#magen-projects-goals-activities",
    "href": "posts/NIH Funding Opportunity.html#magen-projects-goals-activities",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "MAGen Project’s Goals & Activities",
    "text": "MAGen Project’s Goals & Activities\n\nDevelop ML/AI tools integrated with an ELSI framework for genomic research.\nSelect and focus on at least 4 candidate genes with pathogenic variants.\nLead development and cross-validation of tools for specific genes.\nAddress ELSI issues related to ML/AI in genomic medicine applications."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#review-criteria",
    "href": "posts/NIH Funding Opportunity.html#review-criteria",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Review Criteria",
    "text": "Review Criteria\nApplications will be reviewed based on Significance, Investigators, Innovation, Approach, and Environment, with additional considerations for compliance and protection of human subjects.\nApplications proposing new primary data generation or without an ELSI plan will be deemed non-responsive."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#data-sharing",
    "href": "posts/NIH Funding Opportunity.html#data-sharing",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Data Sharing",
    "text": "Data Sharing\nCompliance with NIH data sharing policies is mandatory."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#section-vii-agency-contacts",
    "href": "posts/NIH Funding Opportunity.html#section-vii-agency-contacts",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Section VII: Agency Contacts",
    "text": "Section VII: Agency Contacts\nLists contacts for scientific, financial, and submission-related inquiries."
  },
  {
    "objectID": "posts/NIH Funding Opportunity.html#section-viii-other-information",
    "href": "posts/NIH Funding Opportunity.html#section-viii-other-information",
    "title": "NIH Funding Opportunity for ML/AI Tools in Genomic Translational Research (MAGen)",
    "section": "Section VIII: Other Information",
    "text": "Section VIII: Other Information\nNotes that recent policy notices might affect applications and provides necessary links to regulations.\n\nAuthority\nThe funding is made under sections 301 and 405 of the Public Health Service Act."
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html",
    "href": "posts/Statistics in the Age of AI.html",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "We are thrilled to share that our session proposal titled “Statistics in the Age of AI: a Town Hall with an Expert Panel” has been officially accepted for inclusion in the Joint Statistical Meetings (JSM) program.\n\n\n\nScheduled Time: Monday, 2:00 – 3:50 p.m.\nSession Status: Accepted\n\n\n\n\nCould all proposers confirm if the provided abstract is the finalized version for the program? Should there be any revisions, please furnish the updated abstract at your earliest opportunity.\n\n\n\nThis panel aims to stimulate an open discussion among JSM attendees on the evolving role of statistics in the rapidly advancing field of artificial intelligence. It features a distinguished panel of statisticians who will share their experience, observation and thinking on how statistical research, statistics departments and statisticians are being empowered, challenged and potentially reshaped by AI research. The session will also have an open Q&A and discussion session where both the panelists and sessions participants share their views on some of the hardest questions faced by the statistical community about research impacts, funding and resources, talent pipeline, ethical considerations, and the future of statistical research.\n\n\n\nThe discussion will be enriched by contributions from the following experts:\n\nDavid Donoho\nXihong Lin\nBhramar Mukherjee\nDan Nettleton\nRebecca Nugent\nAbel Rodriguez\nEric Xing\n\n\n\n\nGuiding our conversation will be:\n\nTian Zheng\nHongtu Zhu\n\nWe eagerly anticipate a session that promises to be highly insightful and engaging."
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html#session-details",
    "href": "posts/Statistics in the Age of AI.html#session-details",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "Scheduled Time: Monday, 2:00 – 3:50 p.m.\nSession Status: Accepted"
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html#abstract-confirmation",
    "href": "posts/Statistics in the Age of AI.html#abstract-confirmation",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "Could all proposers confirm if the provided abstract is the finalized version for the program? Should there be any revisions, please furnish the updated abstract at your earliest opportunity."
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html#session-abstract",
    "href": "posts/Statistics in the Age of AI.html#session-abstract",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "This panel aims to stimulate an open discussion among JSM attendees on the evolving role of statistics in the rapidly advancing field of artificial intelligence. It features a distinguished panel of statisticians who will share their experience, observation and thinking on how statistical research, statistics departments and statisticians are being empowered, challenged and potentially reshaped by AI research. The session will also have an open Q&A and discussion session where both the panelists and sessions participants share their views on some of the hardest questions faced by the statistical community about research impacts, funding and resources, talent pipeline, ethical considerations, and the future of statistical research."
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html#panelists",
    "href": "posts/Statistics in the Age of AI.html#panelists",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "The discussion will be enriched by contributions from the following experts:\n\nDavid Donoho\nXihong Lin\nBhramar Mukherjee\nDan Nettleton\nRebecca Nugent\nAbel Rodriguez\nEric Xing"
  },
  {
    "objectID": "posts/Statistics in the Age of AI.html#moderators",
    "href": "posts/Statistics in the Age of AI.html#moderators",
    "title": "Statistics in the Age of AI: a Town Hall with an Expert Panel Accepted for JSM Program",
    "section": "",
    "text": "Guiding our conversation will be:\n\nTian Zheng\nHongtu Zhu\n\nWe eagerly anticipate a session that promises to be highly insightful and engaging."
  },
  {
    "objectID": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html",
    "href": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html",
    "title": "NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)",
    "section": "",
    "text": "The National Science Foundation (NSF) has released a solicitation for the Research Training Groups in the Mathematical Sciences (RTG) program, a key initiative aimed at bolstering the United States’ scientific competitiveness by fostering the next generation of mathematical sciences professionals. The RTG program encourages US institutions to establish innovative research training environments for both graduate and undergraduate students, with an optional inclusion of postdoctoral researchers."
  },
  {
    "objectID": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#highlights-of-the-rtg-program-for-2024-2025",
    "href": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#highlights-of-the-rtg-program-for-2024-2025",
    "title": "NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)",
    "section": "Highlights of the RTG Program for 2024-2025:",
    "text": "Highlights of the RTG Program for 2024-2025:\n\nProposals are invited across all fields within mathematical sciences, particularly those integrating research with emerging areas like Artificial Intelligence, Biotechnology, Quantum Computing, and Cybersecurity.\nProjects are expected to enhance research training and focus on sustained professional development within the mathematical sciences community."
  },
  {
    "objectID": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#proposal-submission-and-award-information",
    "href": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#proposal-submission-and-award-information",
    "title": "NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)",
    "section": "Proposal Submission and Award Information:",
    "text": "Proposal Submission and Award Information:\n\nFull Proposal Deadline: August 13, 2024\nEstimated number of awards: 3 to 10\nAnticipated funding amount: $400,000 to $600,000 per year, with a total of $12 million available."
  },
  {
    "objectID": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#eligibility-criteria",
    "href": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#eligibility-criteria",
    "title": "NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)",
    "section": "Eligibility Criteria:",
    "text": "Eligibility Criteria:\n\nProposals may be submitted by US-based academic institutions granting doctoral degrees in the mathematical sciences.\nThere are no principal investigator (PI) restrictions. However, commitment is taken into account, as an individual cannot serve as PI or co-PI on more than one RTG proposal or award simultaneously.\nParticipants, including trainees, must be US citizens, nationals, or permanent residents."
  },
  {
    "objectID": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#application-instructions",
    "href": "posts/NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG).html#application-instructions",
    "title": "NSF Announces Funding Opportunity for Research Training Groups in the Mathematical Sciences (RTG)",
    "section": "Application Instructions:",
    "text": "Application Instructions:\n\nProposals must adhere to the NSF Proposal & Award Policies & Procedures Guide (PAPPG).\nBoth new and renewal proposals must follow the updated submission guidelines, which reflect changes including optional inclusion of undergraduates and postdocs, new funding alignments, and the latest NSF strategic plan priorities.\n\nThis solicitation emphasizes the interdisciplinary nature of advanced research training and promotes a broad and inclusive approach to education in the mathematical sciences. For more detailed information and application specifics, visit the NSF program solicitation page."
  }
]